{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPAvghWv6XDRyvp+TttK7HS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitalyGladyshev/NeuroN/blob/master/HW_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPSMhCGJuP2d",
        "colab_type": "text"
      },
      "source": [
        "# ДЗ_05\n",
        "\n",
        "## Задание 1\n",
        "\n",
        "Попробуйте обучить нейронную сеть LSTM на любом другом датасете. Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfhdkC3XuMIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, SimpleRNN, GRU\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "from tensorflow.keras.callbacks import EarlyStopping \n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from typing import List, Tuple"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQx1ew4l7zmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
        "    \"\"\"\n",
        "    Вычисление доверительного интервала.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    scores: List[float / int]\n",
        "        Список с оценками изучаемой величины.\n",
        "\n",
        "    conf_interval: float, optional, default = 0.95\n",
        "        Уровень доверия для построения интервала.\n",
        "        Опциональный параметр, по умолчанию, равен 0.95.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    conf_interval: Tuple[float]\n",
        "        Кортеж с границами доверительного интервала.\n",
        "\n",
        "    \"\"\"\n",
        "    left_bound = np.percentile(\n",
        "        scores, ((1 - conf_interval) / 2) * 100\n",
        "    )\n",
        "    right_bound = np.percentile(\n",
        "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
        "    )\n",
        "\n",
        "    return left_bound, right_bound"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4mU1vzdi407",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# files.upload()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K5mW-QsjHWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca96b4ba-b07a-4115-9832-b4983edf6a26"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  shakespear.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqLAZgBZyqJq",
        "colab_type": "text"
      },
      "source": [
        "## Базовый вариант"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2CvDIgeyo8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=1000)\n",
        "data = open('shakespear.txt').read()\n",
        "corpus = data.lower().split(\"\\n\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MllaDJA42_W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh2j7Csn2_Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback = EarlyStopping(monitor='val_loss', patience=10)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgDooyMc2_KN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2b116317-fd5a-43eb-a75c-c322f653b7fa"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
        "#model.add(Bidirectional(LSTM(50, return_sequences = True)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(LSTM(10))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 14, 10)            35430     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 10)                840       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1771)              19481     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,333,947\n",
            "Trainable params: 6,333,947\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98l1M1AM3PIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "31c52f4a-4b9d-4ecd-ed37-d9d9b7b622be"
      },
      "source": [
        "history = model.fit(predictors, label, epochs=100, validation_split=0.2, callbacks=[callback],verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 23s 69ms/step - loss: 6.2136 - accuracy: 0.0309 - val_loss: 5.8145 - val_accuracy: 0.0310\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.7499 - accuracy: 0.0334 - val_loss: 5.7827 - val_accuracy: 0.0310\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.7150 - accuracy: 0.0346 - val_loss: 5.7575 - val_accuracy: 0.0310\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.6752 - accuracy: 0.0367 - val_loss: 5.7422 - val_accuracy: 0.0397\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.6317 - accuracy: 0.0412 - val_loss: 5.7222 - val_accuracy: 0.0427\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.5892 - accuracy: 0.0416 - val_loss: 5.6865 - val_accuracy: 0.0427\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.5416 - accuracy: 0.0438 - val_loss: 5.6725 - val_accuracy: 0.0458\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.5019 - accuracy: 0.0454 - val_loss: 5.6588 - val_accuracy: 0.0488\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.4718 - accuracy: 0.0483 - val_loss: 5.6377 - val_accuracy: 0.0526\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.4481 - accuracy: 0.0526 - val_loss: 5.6488 - val_accuracy: 0.0488\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.4239 - accuracy: 0.0548 - val_loss: 5.6402 - val_accuracy: 0.0514\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.4004 - accuracy: 0.0569 - val_loss: 5.6974 - val_accuracy: 0.0492\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.3739 - accuracy: 0.0589 - val_loss: 5.6346 - val_accuracy: 0.0575\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.3536 - accuracy: 0.0584 - val_loss: 5.6386 - val_accuracy: 0.0590\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 23s 69ms/step - loss: 5.3264 - accuracy: 0.0608 - val_loss: 5.6447 - val_accuracy: 0.0560\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.3053 - accuracy: 0.0622 - val_loss: 5.6648 - val_accuracy: 0.0560\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.2806 - accuracy: 0.0637 - val_loss: 5.6372 - val_accuracy: 0.0556\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.2576 - accuracy: 0.0644 - val_loss: 5.6477 - val_accuracy: 0.0594\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 22s 68ms/step - loss: 5.2379 - accuracy: 0.0645 - val_loss: 5.6440 - val_accuracy: 0.0628\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 22s 68ms/step - loss: 5.2142 - accuracy: 0.0667 - val_loss: 5.6743 - val_accuracy: 0.0571\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 22s 68ms/step - loss: 5.1947 - accuracy: 0.0685 - val_loss: 5.6703 - val_accuracy: 0.0658\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 22s 67ms/step - loss: 5.1751 - accuracy: 0.0719 - val_loss: 5.6483 - val_accuracy: 0.0605\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 22s 68ms/step - loss: 5.1529 - accuracy: 0.0739 - val_loss: 5.6568 - val_accuracy: 0.0669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEiHQK0i3PCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "0711512b-6b6d-4a20-d37e-38411f17134b"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "acc_v = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "loss_v = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Train')\n",
        "plt.plot(epochs, acc_v, 'r', label='Test')\n",
        "plt.legend()\n",
        "plt.title('accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Train')\n",
        "plt.plot(epochs, loss_v, 'r', label='Test')\n",
        "plt.title('loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwom0NUj3wR9",
        "colab_type": "text"
      },
      "source": [
        "## Варианты топологий"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm2c4vbF3ajJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def net_gen(lay_name='GRU', func_act=\"tanh\", units=10):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Embedding(total_words, units, input_length=max_sequence_len-1))\n",
        "    #model.add(Bidirectional(LSTM(50, return_sequences = True)))\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(eval(lay_name)(units, activation=func_act))    # model.add(lay_name(units, activation=func_act))\n",
        "    model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        " \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG6jyBn-8a4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def net_iter(model, ep=10, batch_size=512):\n",
        "    history = model.fit(predictors, \n",
        "                        label, \n",
        "                        epochs=ep, \n",
        "                        validation_split=0.2,\n",
        "                        verbose=1)\n",
        "    return history.history"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1hvv-Y58fCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7b5074e-8f76-40e7-ec44-a79ba608b58d"
      },
      "source": [
        "summary_data = pd.DataFrame(data=[[0, 0, 0, 0, 0, 0, 0, 0]], \n",
        "                            columns=['layers', 'func_act', 'unit_number', 'mean_train_accuracy', 'mean_val_accuracy', 'variance', 'l_b', 'r_b'])\n",
        "cnt = 0\n",
        "lay_name = ['SimpleRNN', 'LSTM', 'GRU']   # [SimpleRNN, LSTM, GRU] \n",
        "f_act = ['tanh', 'sigmoid']    # 'relu', \n",
        "unit_number = [10, 20]    # , 50\n",
        "epochs = 5\n",
        "\n",
        "for l_n in lay_name:\n",
        "    for f_a in f_act:\n",
        "        for u_n in unit_number:\n",
        "            err_accuracy = []\n",
        "            err_val_accuracy = []\n",
        "            print(f\"Модель: слой {l_n}, функция активации {f_a}, число блоков {u_n}, эпох {epochs}\\n\")\n",
        "            model = net_gen(lay_name=l_n, func_act=f_a, units=u_n)\n",
        "            model.summary()\n",
        "            for i in range(3):  # range(5):\n",
        "                print(f\"\\tИтерация: {i+1}\")\n",
        "                hist = net_iter(model, ep=epochs)\n",
        "                err_accuracy.append(hist['accuracy'][-1])\n",
        "                err_val_accuracy.append(hist['val_accuracy'][-1])\n",
        "\n",
        "            vr = np.var(err_val_accuracy)\n",
        "            l_b, r_b = calculate_confidence_interval(err_val_accuracy)\n",
        "            mean_err_accuracy, mean_err_val_accuracy = np.mean(err_accuracy), np.mean(err_val_accuracy)\n",
        "            print(f\"Ошибки на train. Средняя: {mean_err_accuracy} список: {err_accuracy}\")\n",
        "            print(f\"Ошибки на valid. Средняя: {mean_err_val_accuracy} список: {err_val_accuracy}\")\n",
        "            print(f\"Дисперсия ошибки на valid: {vr}\")\n",
        "            print(f\"Доверительный интервал: {l_b} - {r_b}\\n\\n\")\n",
        "            summary_data.loc[cnt, ['layers', 'func_act', 'unit_number', 'mean_train_accuracy', \n",
        "                                   'mean_val_accuracy', 'variance', 'l_b', 'r_b']] = [l_n, f_a, u_n, \n",
        "                                            np.mean(err_accuracy), np.mean(err_val_accuracy), vr, l_b, r_b]\n",
        "            cnt += 1"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Модель: слой SimpleRNN, функция активации tanh, число блоков 10, эпох 5\n",
            "\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 14, 10)            35430     \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1771)              19481     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,333,317\n",
            "Trainable params: 6,333,317\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 6.1466 - accuracy: 0.0330 - val_loss: 5.7802 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.7022 - accuracy: 0.0354 - val_loss: 5.7382 - val_accuracy: 0.0314\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.6388 - accuracy: 0.0396 - val_loss: 5.7311 - val_accuracy: 0.0371\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 25s 77ms/step - loss: 5.5715 - accuracy: 0.0431 - val_loss: 5.7035 - val_accuracy: 0.0454\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.4991 - accuracy: 0.0457 - val_loss: 5.6831 - val_accuracy: 0.0431\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 25s 75ms/step - loss: 5.4318 - accuracy: 0.0498 - val_loss: 5.6855 - val_accuracy: 0.0431\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3678 - accuracy: 0.0540 - val_loss: 5.6837 - val_accuracy: 0.0526\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.3117 - accuracy: 0.0584 - val_loss: 5.7174 - val_accuracy: 0.0477\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.2634 - accuracy: 0.0639 - val_loss: 5.7079 - val_accuracy: 0.0556\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 25s 77ms/step - loss: 5.2149 - accuracy: 0.0662 - val_loss: 5.7394 - val_accuracy: 0.0503\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.1700 - accuracy: 0.0694 - val_loss: 5.7430 - val_accuracy: 0.0552\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.1224 - accuracy: 0.0729 - val_loss: 5.7546 - val_accuracy: 0.0594\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.0846 - accuracy: 0.0774 - val_loss: 5.7840 - val_accuracy: 0.0598\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 24s 74ms/step - loss: 5.0419 - accuracy: 0.0803 - val_loss: 5.8305 - val_accuracy: 0.0616\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 77ms/step - loss: 5.0016 - accuracy: 0.0825 - val_loss: 5.8804 - val_accuracy: 0.0635\n",
            "Ошибки на train. Средняя: 0.06479379410545032 список: [0.045686718076467514, 0.06621263921260834, 0.08248202502727509]\n",
            "Ошибки на valid. Средняя: 0.052319719145695366 список: [0.0431164912879467, 0.050302572548389435, 0.06354009360074997]\n",
            "Дисперсия ошибки на valid: 7.15550287694353e-05\n",
            "Доверительный интервал: 0.04347579535096884 - 0.06287821754813194\n",
            "\n",
            "\n",
            "Модель: слой SimpleRNN, функция активации tanh, число блоков 20, эпох 5\n",
            "\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 14, 20)            70860     \n",
            "_________________________________________________________________\n",
            "simple_rnn_6 (SimpleRNN)     (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1771)              37191     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,387,067\n",
            "Trainable params: 6,387,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 32s 96ms/step - loss: 6.1442 - accuracy: 0.0320 - val_loss: 5.7959 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.6900 - accuracy: 0.0359 - val_loss: 5.7376 - val_accuracy: 0.0333\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 25s 77ms/step - loss: 5.6146 - accuracy: 0.0371 - val_loss: 5.7613 - val_accuracy: 0.0390\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.5342 - accuracy: 0.0437 - val_loss: 5.6934 - val_accuracy: 0.0435\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.4469 - accuracy: 0.0476 - val_loss: 5.6891 - val_accuracy: 0.0454\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.3635 - accuracy: 0.0521 - val_loss: 5.6830 - val_accuracy: 0.0499\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.2819 - accuracy: 0.0599 - val_loss: 5.7064 - val_accuracy: 0.0571\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.2089 - accuracy: 0.0642 - val_loss: 5.7183 - val_accuracy: 0.0579\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.1403 - accuracy: 0.0714 - val_loss: 5.8042 - val_accuracy: 0.0579\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 29s 88ms/step - loss: 5.0740 - accuracy: 0.0772 - val_loss: 5.7750 - val_accuracy: 0.0639\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.0107 - accuracy: 0.0791 - val_loss: 5.8074 - val_accuracy: 0.0669\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 4.9501 - accuracy: 0.0845 - val_loss: 5.8455 - val_accuracy: 0.0632\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 28s 86ms/step - loss: 4.8919 - accuracy: 0.0895 - val_loss: 5.8943 - val_accuracy: 0.0594\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 4.8344 - accuracy: 0.0916 - val_loss: 5.9898 - val_accuracy: 0.0685\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 4.7799 - accuracy: 0.0967 - val_loss: 5.9992 - val_accuracy: 0.0598\n",
            "Ошибки на train. Средняя: 0.07381132617592812 список: [0.04757850989699364, 0.0771850198507309, 0.09667044878005981]\n",
            "Ошибки на valid. Средняя: 0.05635400985678037 список: [0.045385777950286865, 0.06391830742359161, 0.05975794419646263]\n",
            "Дисперсия ошибки на valid: 6.303582594091891e-05\n",
            "Доверительный интервал: 0.04610438626259566 - 0.06371028926223517\n",
            "\n",
            "\n",
            "Модель: слой SimpleRNN, функция активации sigmoid, число блоков 10, эпох 5\n",
            "\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 14, 10)            35430     \n",
            "_________________________________________________________________\n",
            "simple_rnn_7 (SimpleRNN)     (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1771)              19481     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,333,317\n",
            "Trainable params: 6,333,317\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 6.1403 - accuracy: 0.0312 - val_loss: 5.7970 - val_accuracy: 0.0291\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 31s 93ms/step - loss: 5.7156 - accuracy: 0.0350 - val_loss: 5.7450 - val_accuracy: 0.0310\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.6711 - accuracy: 0.0365 - val_loss: 5.7330 - val_accuracy: 0.0340\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.6404 - accuracy: 0.0385 - val_loss: 5.7126 - val_accuracy: 0.0378\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.6052 - accuracy: 0.0400 - val_loss: 5.7074 - val_accuracy: 0.0431\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 29s 87ms/step - loss: 5.5615 - accuracy: 0.0385 - val_loss: 5.6976 - val_accuracy: 0.0378\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.5246 - accuracy: 0.0411 - val_loss: 5.6558 - val_accuracy: 0.0450\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.4928 - accuracy: 0.0425 - val_loss: 5.6676 - val_accuracy: 0.0431\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.4634 - accuracy: 0.0432 - val_loss: 5.6411 - val_accuracy: 0.0465\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.4435 - accuracy: 0.0473 - val_loss: 5.6421 - val_accuracy: 0.0469\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 28s 86ms/step - loss: 5.4298 - accuracy: 0.0478 - val_loss: 5.6448 - val_accuracy: 0.0480\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.4118 - accuracy: 0.0530 - val_loss: 5.6412 - val_accuracy: 0.0507\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 77ms/step - loss: 5.3973 - accuracy: 0.0525 - val_loss: 5.6418 - val_accuracy: 0.0518\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3834 - accuracy: 0.0550 - val_loss: 5.6312 - val_accuracy: 0.0545\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.3704 - accuracy: 0.0564 - val_loss: 5.6466 - val_accuracy: 0.0545\n",
            "Ошибки на train. Средняя: 0.04789380729198456 список: [0.04001135006546974, 0.0472947396337986, 0.05637533217668533]\n",
            "Ошибки на valid. Средняя: 0.048159354676802955 список: [0.0431164912879467, 0.04689863696694374, 0.05446293577551842]\n",
            "Дисперсия ошибки на valid: 2.2251671656900756e-05\n",
            "Доверительный интервал: 0.04330559857189656 - 0.05408472083508968\n",
            "\n",
            "\n",
            "Модель: слой SimpleRNN, функция активации sigmoid, число блоков 20, эпох 5\n",
            "\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 14, 20)            70860     \n",
            "_________________________________________________________________\n",
            "simple_rnn_8 (SimpleRNN)     (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1771)              37191     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,387,067\n",
            "Trainable params: 6,387,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 6.1490 - accuracy: 0.0348 - val_loss: 5.7853 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 28s 85ms/step - loss: 5.7095 - accuracy: 0.0351 - val_loss: 5.7529 - val_accuracy: 0.0269\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.6651 - accuracy: 0.0360 - val_loss: 5.7376 - val_accuracy: 0.0310\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 77ms/step - loss: 5.6367 - accuracy: 0.0373 - val_loss: 5.7257 - val_accuracy: 0.0318\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.6055 - accuracy: 0.0383 - val_loss: 5.7120 - val_accuracy: 0.0412\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 25s 77ms/step - loss: 5.5631 - accuracy: 0.0408 - val_loss: 5.6897 - val_accuracy: 0.0446\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.5215 - accuracy: 0.0429 - val_loss: 5.6605 - val_accuracy: 0.0439\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.4868 - accuracy: 0.0459 - val_loss: 5.6555 - val_accuracy: 0.0397\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.4587 - accuracy: 0.0472 - val_loss: 5.6676 - val_accuracy: 0.0484\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.4348 - accuracy: 0.0493 - val_loss: 5.6438 - val_accuracy: 0.0458\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 25s 77ms/step - loss: 5.4122 - accuracy: 0.0516 - val_loss: 5.6390 - val_accuracy: 0.0450\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.3924 - accuracy: 0.0537 - val_loss: 5.6338 - val_accuracy: 0.0533\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 25s 75ms/step - loss: 5.3658 - accuracy: 0.0556 - val_loss: 5.6416 - val_accuracy: 0.0477\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.3341 - accuracy: 0.0568 - val_loss: 5.6078 - val_accuracy: 0.0598\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.2993 - accuracy: 0.0600 - val_loss: 5.6114 - val_accuracy: 0.0590\n",
            "Ошибки на train. Средняя: 0.04918653021256129 список: [0.03830873966217041, 0.04928112030029297, 0.05996973067522049]\n",
            "Ошибки на valid. Средняя: 0.048663641015688576 список: [0.04122541472315788, 0.04576399549841881, 0.059001512825489044]\n",
            "Дисперсия ошибки на valid: 5.686891602019492e-05\n",
            "Доверительный интервал: 0.04145234376192093 - 0.058339636959135535\n",
            "\n",
            "\n",
            "Модель: слой LSTM, функция активации tanh, число блоков 10, эпох 5\n",
            "\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 14, 10)            35430     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 10)                840       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1771)              19481     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,333,947\n",
            "Trainable params: 6,333,947\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 28s 83ms/step - loss: 6.2208 - accuracy: 0.0325 - val_loss: 5.8084 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.7491 - accuracy: 0.0342 - val_loss: 5.7846 - val_accuracy: 0.0310\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.7073 - accuracy: 0.0351 - val_loss: 5.7535 - val_accuracy: 0.0310\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.6586 - accuracy: 0.0371 - val_loss: 5.7335 - val_accuracy: 0.0390\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.6145 - accuracy: 0.0398 - val_loss: 5.7073 - val_accuracy: 0.0393\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.5654 - accuracy: 0.0429 - val_loss: 5.6820 - val_accuracy: 0.0446\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.5167 - accuracy: 0.0442 - val_loss: 5.6641 - val_accuracy: 0.0427\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 77ms/step - loss: 5.4773 - accuracy: 0.0494 - val_loss: 5.6425 - val_accuracy: 0.0537\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.4434 - accuracy: 0.0512 - val_loss: 5.6288 - val_accuracy: 0.0514\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.4166 - accuracy: 0.0556 - val_loss: 5.6380 - val_accuracy: 0.0552\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 28s 85ms/step - loss: 5.3908 - accuracy: 0.0562 - val_loss: 5.6443 - val_accuracy: 0.0575\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3696 - accuracy: 0.0587 - val_loss: 5.6421 - val_accuracy: 0.0605\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3450 - accuracy: 0.0604 - val_loss: 5.6373 - val_accuracy: 0.0594\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3246 - accuracy: 0.0605 - val_loss: 5.6399 - val_accuracy: 0.0613\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.2951 - accuracy: 0.0630 - val_loss: 5.6054 - val_accuracy: 0.0639\n",
            "Ошибки на train. Средняя: 0.05281246080994606 список: [0.03982217237353325, 0.055618613958358765, 0.06299659609794617]\n",
            "Ошибки на valid. Средняя: 0.05282400424281756 список: [0.03933434188365936, 0.055219363421201706, 0.06391830742359161]\n",
            "Дисперсия ошибки на valid: 0.00010359743307483064\n",
            "Доверительный интервал: 0.04012859296053648 - 0.06348336022347212\n",
            "\n",
            "\n",
            "Модель: слой LSTM, функция активации tanh, число блоков 20, эпох 5\n",
            "\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 14, 20)            70860     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 20)                3280      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1771)              37191     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,389,527\n",
            "Trainable params: 6,389,527\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 29s 86ms/step - loss: 6.2121 - accuracy: 0.0322 - val_loss: 5.8101 - val_accuracy: 0.0352\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.7470 - accuracy: 0.0341 - val_loss: 5.7773 - val_accuracy: 0.0310\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.6918 - accuracy: 0.0359 - val_loss: 5.7490 - val_accuracy: 0.0390\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.6400 - accuracy: 0.0395 - val_loss: 5.7182 - val_accuracy: 0.0416\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.5824 - accuracy: 0.0395 - val_loss: 5.6806 - val_accuracy: 0.0397\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.5256 - accuracy: 0.0452 - val_loss: 5.6488 - val_accuracy: 0.0408\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 5.4815 - accuracy: 0.0458 - val_loss: 5.6402 - val_accuracy: 0.0484\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 5.4459 - accuracy: 0.0486 - val_loss: 5.6569 - val_accuracy: 0.0526\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.4119 - accuracy: 0.0546 - val_loss: 5.6214 - val_accuracy: 0.0552\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.3762 - accuracy: 0.0575 - val_loss: 5.6277 - val_accuracy: 0.0545\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.3371 - accuracy: 0.0585 - val_loss: 5.6122 - val_accuracy: 0.0594\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.2959 - accuracy: 0.0658 - val_loss: 5.5913 - val_accuracy: 0.0651\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.2472 - accuracy: 0.0693 - val_loss: 5.6060 - val_accuracy: 0.0681\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.1932 - accuracy: 0.0743 - val_loss: 5.6073 - val_accuracy: 0.0658\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 77ms/step - loss: 5.1430 - accuracy: 0.0754 - val_loss: 5.6060 - val_accuracy: 0.0738\n",
            "Ошибки на train. Средняя: 0.05747887368003527 список: [0.03953840211033821, 0.05751040577888489, 0.07538781315088272]\n",
            "Ошибки на valid. Средняя: 0.05597579355041186 список: [0.03971255570650101, 0.05446293577551842, 0.07375188916921616]\n",
            "Дисперсия ошибки на valid: 0.00019425707308784768\n",
            "Доверительный интервал: 0.04045007470995188 - 0.07278744149953127\n",
            "\n",
            "\n",
            "Модель: слой LSTM, функция активации sigmoid, число блоков 10, эпох 5\n",
            "\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 14, 10)            35430     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 10)                840       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1771)              19481     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,333,947\n",
            "Trainable params: 6,333,947\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 6.1468 - accuracy: 0.0323 - val_loss: 5.8085 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.7204 - accuracy: 0.0356 - val_loss: 5.7489 - val_accuracy: 0.0310\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 25s 77ms/step - loss: 5.6728 - accuracy: 0.0335 - val_loss: 5.7350 - val_accuracy: 0.0310\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.6419 - accuracy: 0.0378 - val_loss: 5.7272 - val_accuracy: 0.0401\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.6082 - accuracy: 0.0391 - val_loss: 5.7023 - val_accuracy: 0.0439\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.5667 - accuracy: 0.0412 - val_loss: 5.6855 - val_accuracy: 0.0393\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.5224 - accuracy: 0.0406 - val_loss: 5.6670 - val_accuracy: 0.0435\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.4910 - accuracy: 0.0426 - val_loss: 5.6396 - val_accuracy: 0.0480\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.4629 - accuracy: 0.0438 - val_loss: 5.6369 - val_accuracy: 0.0465\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.4435 - accuracy: 0.0467 - val_loss: 5.6373 - val_accuracy: 0.0450\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.4269 - accuracy: 0.0495 - val_loss: 5.6465 - val_accuracy: 0.0393\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.4173 - accuracy: 0.0533 - val_loss: 5.6461 - val_accuracy: 0.0514\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.4027 - accuracy: 0.0527 - val_loss: 5.6497 - val_accuracy: 0.0552\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3929 - accuracy: 0.0547 - val_loss: 5.6491 - val_accuracy: 0.0492\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 28s 83ms/step - loss: 5.3789 - accuracy: 0.0548 - val_loss: 5.6674 - val_accuracy: 0.0518\n",
            "Ошибки на train. Средняя: 0.04685332253575325 список: [0.03906545415520668, 0.04672720283269882, 0.05476731061935425]\n",
            "Ошибки на valid. Средняя: 0.046898638208707176 список: [0.04387291893362999, 0.04500756412744522, 0.05181543156504631]\n",
            "Дисперсия ошибки на valid: 1.2301998407111673e-05\n",
            "Доверительный интервал: 0.043929651193320755 - 0.051475038193166255\n",
            "\n",
            "\n",
            "Модель: слой LSTM, функция активации sigmoid, число блоков 20, эпох 5\n",
            "\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 14, 20)            70860     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 20)                3280      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1771)              37191     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,389,527\n",
            "Trainable params: 6,389,527\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 29s 87ms/step - loss: 6.1494 - accuracy: 0.0331 - val_loss: 5.7946 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.7132 - accuracy: 0.0342 - val_loss: 5.7472 - val_accuracy: 0.0310\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 25s 76ms/step - loss: 5.6659 - accuracy: 0.0349 - val_loss: 5.7427 - val_accuracy: 0.0310\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.6390 - accuracy: 0.0366 - val_loss: 5.7542 - val_accuracy: 0.0386\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.6016 - accuracy: 0.0395 - val_loss: 5.7039 - val_accuracy: 0.0435\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.5562 - accuracy: 0.0393 - val_loss: 5.6775 - val_accuracy: 0.0412\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.5179 - accuracy: 0.0415 - val_loss: 5.6661 - val_accuracy: 0.0397\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.4895 - accuracy: 0.0416 - val_loss: 5.6616 - val_accuracy: 0.0484\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.4612 - accuracy: 0.0447 - val_loss: 5.6689 - val_accuracy: 0.0424\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.4400 - accuracy: 0.0445 - val_loss: 5.6490 - val_accuracy: 0.0465\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.4271 - accuracy: 0.0519 - val_loss: 5.6705 - val_accuracy: 0.0450\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.4074 - accuracy: 0.0527 - val_loss: 5.6441 - val_accuracy: 0.0503\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.3949 - accuracy: 0.0558 - val_loss: 5.6349 - val_accuracy: 0.0545\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.3762 - accuracy: 0.0586 - val_loss: 5.6364 - val_accuracy: 0.0545\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.3570 - accuracy: 0.0581 - val_loss: 5.6303 - val_accuracy: 0.0541\n",
            "Ошибки на train. Средняя: 0.04735780010620753 список: [0.03953840211033821, 0.04445705562829971, 0.058077942579984665]\n",
            "Ошибки на valid. Средняя: 0.04803328340252241 список: [0.043494705110788345, 0.0465204231441021, 0.05408472195267677]\n",
            "Дисперсия ошибки на valid: 1.9835782532667207e-05\n",
            "Доверительный интервал: 0.04364599101245403 - 0.053706507012248036\n",
            "\n",
            "\n",
            "Модель: слой GRU, функция активации tanh, число блоков 10, эпох 5\n",
            "\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, 14, 10)            35430     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 10)                660       \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1771)              19481     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,333,767\n",
            "Trainable params: 6,333,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 6.2435 - accuracy: 0.0325 - val_loss: 5.8195 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 5.7450 - accuracy: 0.0366 - val_loss: 5.7615 - val_accuracy: 0.0352\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.6822 - accuracy: 0.0345 - val_loss: 5.7289 - val_accuracy: 0.0344\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.6246 - accuracy: 0.0403 - val_loss: 5.6854 - val_accuracy: 0.0477\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.5574 - accuracy: 0.0436 - val_loss: 5.6462 - val_accuracy: 0.0439\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.5028 - accuracy: 0.0463 - val_loss: 5.6345 - val_accuracy: 0.0503\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 5.4581 - accuracy: 0.0516 - val_loss: 5.6356 - val_accuracy: 0.0537\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 28s 86ms/step - loss: 5.4162 - accuracy: 0.0525 - val_loss: 5.6041 - val_accuracy: 0.0518\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.3733 - accuracy: 0.0569 - val_loss: 5.5947 - val_accuracy: 0.0548\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3286 - accuracy: 0.0588 - val_loss: 5.5845 - val_accuracy: 0.0548\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.2875 - accuracy: 0.0617 - val_loss: 5.5947 - val_accuracy: 0.0601\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.2474 - accuracy: 0.0641 - val_loss: 5.5773 - val_accuracy: 0.0666\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.2143 - accuracy: 0.0658 - val_loss: 5.5962 - val_accuracy: 0.0722\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.1783 - accuracy: 0.0729 - val_loss: 5.5988 - val_accuracy: 0.0666\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.1504 - accuracy: 0.0715 - val_loss: 5.6312 - val_accuracy: 0.0696\n",
            "Ошибки на train. Средняя: 0.05798335373401642 список: [0.0436057522892952, 0.058834657073020935, 0.07150965183973312]\n",
            "Ошибки на valid. Средняя: 0.05610186606645584 список: [0.04387291893362999, 0.05484114959836006, 0.06959152966737747]\n",
            "Дисперсия ошибки на valid: 0.00011103585935213582\n",
            "Доверительный интервал: 0.0444213304668665 - 0.0688540106639266\n",
            "\n",
            "\n",
            "Модель: слой GRU, функция активации tanh, число блоков 20, эпох 5\n",
            "\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_18 (Embedding)     (None, 14, 20)            70860     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 20)                2520      \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1771)              37191     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,388,767\n",
            "Trainable params: 6,388,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 6.2198 - accuracy: 0.0322 - val_loss: 5.8059 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.7112 - accuracy: 0.0369 - val_loss: 5.7457 - val_accuracy: 0.0382\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.6314 - accuracy: 0.0404 - val_loss: 5.6965 - val_accuracy: 0.0427\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.5484 - accuracy: 0.0424 - val_loss: 5.6497 - val_accuracy: 0.0518\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.4779 - accuracy: 0.0509 - val_loss: 5.6324 - val_accuracy: 0.0545\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.3977 - accuracy: 0.0570 - val_loss: 5.5923 - val_accuracy: 0.0598\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.3338 - accuracy: 0.0576 - val_loss: 5.5713 - val_accuracy: 0.0564\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.2789 - accuracy: 0.0608 - val_loss: 5.5699 - val_accuracy: 0.0620\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 5.2322 - accuracy: 0.0650 - val_loss: 5.5950 - val_accuracy: 0.0601\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.1839 - accuracy: 0.0720 - val_loss: 5.5898 - val_accuracy: 0.0647\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 28s 83ms/step - loss: 5.1319 - accuracy: 0.0778 - val_loss: 5.5877 - val_accuracy: 0.0711\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 29s 87ms/step - loss: 5.0763 - accuracy: 0.0806 - val_loss: 5.6221 - val_accuracy: 0.0730\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.0206 - accuracy: 0.0867 - val_loss: 5.5968 - val_accuracy: 0.0692\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 4.9716 - accuracy: 0.0879 - val_loss: 5.6234 - val_accuracy: 0.0738\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 4.9270 - accuracy: 0.0933 - val_loss: 5.6451 - val_accuracy: 0.0730\n",
            "Ошибки на train. Средняя: 0.07204565405845642 список: [0.050889141857624054, 0.07198259234428406, 0.09326522797346115]\n",
            "Ошибки на valid. Средняя: 0.06404437745610873 список: [0.05446293577551842, 0.0646747350692749, 0.07299546152353287]\n",
            "Дисперсия ошибки на valid: 5.744109379370803e-05\n",
            "Доверительный интервал: 0.054973525740206246 - 0.07257942520081997\n",
            "\n",
            "\n",
            "Модель: слой GRU, функция активации sigmoid, число блоков 10, эпох 5\n",
            "\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 14, 10)            35430     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 10)                660       \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1771)              19481     \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,333,767\n",
            "Trainable params: 6,333,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 6.1435 - accuracy: 0.0340 - val_loss: 5.8008 - val_accuracy: 0.0352\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.7208 - accuracy: 0.0352 - val_loss: 5.7867 - val_accuracy: 0.0310\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.6741 - accuracy: 0.0360 - val_loss: 5.7302 - val_accuracy: 0.0352\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.6420 - accuracy: 0.0385 - val_loss: 5.7214 - val_accuracy: 0.0374\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.6109 - accuracy: 0.0406 - val_loss: 5.7018 - val_accuracy: 0.0408\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.5618 - accuracy: 0.0415 - val_loss: 5.6725 - val_accuracy: 0.0386\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.5241 - accuracy: 0.0423 - val_loss: 5.6654 - val_accuracy: 0.0465\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 79ms/step - loss: 5.4885 - accuracy: 0.0448 - val_loss: 5.6548 - val_accuracy: 0.0424\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.4609 - accuracy: 0.0483 - val_loss: 5.6354 - val_accuracy: 0.0499\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.4441 - accuracy: 0.0505 - val_loss: 5.6360 - val_accuracy: 0.0511\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.4262 - accuracy: 0.0512 - val_loss: 5.6525 - val_accuracy: 0.0518\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.4117 - accuracy: 0.0534 - val_loss: 5.6428 - val_accuracy: 0.0530\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 81ms/step - loss: 5.3942 - accuracy: 0.0548 - val_loss: 5.6237 - val_accuracy: 0.0548\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 28s 83ms/step - loss: 5.3784 - accuracy: 0.0572 - val_loss: 5.6478 - val_accuracy: 0.0514\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 5.3617 - accuracy: 0.0589 - val_loss: 5.6337 - val_accuracy: 0.0511\n",
            "Ошибки на train. Средняя: 0.05000630517800649 список: [0.04057888686656952, 0.05051078274846077, 0.05892924591898918]\n",
            "Ошибки на valid. Средняя: 0.04765506709615389 список: [0.04084720090031624, 0.05105900019407272, 0.05105900019407272]\n",
            "Дисперсия ошибки на valid: 2.317352107021454e-05\n",
            "Доверительный интервал: 0.04135779086500407 - 0.05105900019407272\n",
            "\n",
            "\n",
            "Модель: слой GRU, функция активации sigmoid, число блоков 20, эпох 5\n",
            "\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_20 (Embedding)     (None, 14, 20)            70860     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 20)                2520      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1771)              37191     \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 3543)              6278196   \n",
            "=================================================================\n",
            "Total params: 6,388,767\n",
            "Trainable params: 6,388,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tИтерация: 1\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 6.1463 - accuracy: 0.0326 - val_loss: 5.8203 - val_accuracy: 0.0310\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.7147 - accuracy: 0.0343 - val_loss: 5.7518 - val_accuracy: 0.0310\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.6668 - accuracy: 0.0356 - val_loss: 5.7463 - val_accuracy: 0.0310\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 27s 83ms/step - loss: 5.6393 - accuracy: 0.0384 - val_loss: 5.7295 - val_accuracy: 0.0333\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 28s 83ms/step - loss: 5.6108 - accuracy: 0.0390 - val_loss: 5.7079 - val_accuracy: 0.0374\n",
            "\tИтерация: 2\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 27s 80ms/step - loss: 5.5673 - accuracy: 0.0390 - val_loss: 5.6822 - val_accuracy: 0.0412\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 28s 86ms/step - loss: 5.5230 - accuracy: 0.0433 - val_loss: 5.6659 - val_accuracy: 0.0344\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 28s 83ms/step - loss: 5.4906 - accuracy: 0.0446 - val_loss: 5.6505 - val_accuracy: 0.0420\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 28s 84ms/step - loss: 5.4639 - accuracy: 0.0460 - val_loss: 5.6392 - val_accuracy: 0.0454\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 29s 88ms/step - loss: 5.4431 - accuracy: 0.0473 - val_loss: 5.6431 - val_accuracy: 0.0477\n",
            "\tИтерация: 3\n",
            "Epoch 1/5\n",
            "331/331 [==============================] - 26s 80ms/step - loss: 5.4239 - accuracy: 0.0509 - val_loss: 5.6519 - val_accuracy: 0.0511\n",
            "Epoch 2/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.4085 - accuracy: 0.0532 - val_loss: 5.6471 - val_accuracy: 0.0514\n",
            "Epoch 3/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3891 - accuracy: 0.0565 - val_loss: 5.6331 - val_accuracy: 0.0503\n",
            "Epoch 4/5\n",
            "331/331 [==============================] - 26s 78ms/step - loss: 5.3682 - accuracy: 0.0576 - val_loss: 5.6401 - val_accuracy: 0.0541\n",
            "Epoch 5/5\n",
            "331/331 [==============================] - 27s 82ms/step - loss: 5.3387 - accuracy: 0.0609 - val_loss: 5.6084 - val_accuracy: 0.0598\n",
            "Ошибки на train. Средняя: 0.04906041050950686 список: [0.038970865309238434, 0.0472947396337986, 0.06091562658548355]\n",
            "Ошибки на valid. Средняя: 0.04828542719284693 список: [0.03744326904416084, 0.04765506833791733, 0.05975794419646263]\n",
            "Дисперсия ошибки на valid: 8.318946400178654e-05\n",
            "Доверительный интервал: 0.037953859008848664 - 0.05915280040353536\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oav5lOK8fSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "9f4f471b-e682-488f-866b-07f3c8e67941"
      },
      "source": [
        "summary_data"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>layers</th>\n",
              "      <th>func_act</th>\n",
              "      <th>unit_number</th>\n",
              "      <th>mean_train_accuracy</th>\n",
              "      <th>mean_val_accuracy</th>\n",
              "      <th>variance</th>\n",
              "      <th>l_b</th>\n",
              "      <th>r_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.064794</td>\n",
              "      <td>0.052320</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.043476</td>\n",
              "      <td>0.062878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.073811</td>\n",
              "      <td>0.056354</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.046104</td>\n",
              "      <td>0.063710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.047894</td>\n",
              "      <td>0.048159</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.043306</td>\n",
              "      <td>0.054085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.049187</td>\n",
              "      <td>0.048664</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.041452</td>\n",
              "      <td>0.058340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>tanh</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.052812</td>\n",
              "      <td>0.052824</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.040129</td>\n",
              "      <td>0.063483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>tanh</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.057479</td>\n",
              "      <td>0.055976</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.040450</td>\n",
              "      <td>0.072787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.046853</td>\n",
              "      <td>0.046899</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.043930</td>\n",
              "      <td>0.051475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.047358</td>\n",
              "      <td>0.048033</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.043646</td>\n",
              "      <td>0.053707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GRU</td>\n",
              "      <td>tanh</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.057983</td>\n",
              "      <td>0.056102</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.044421</td>\n",
              "      <td>0.068854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GRU</td>\n",
              "      <td>tanh</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.072046</td>\n",
              "      <td>0.064044</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.054974</td>\n",
              "      <td>0.072579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GRU</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.050006</td>\n",
              "      <td>0.047655</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.041358</td>\n",
              "      <td>0.051059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>GRU</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.049060</td>\n",
              "      <td>0.048285</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.037954</td>\n",
              "      <td>0.059153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       layers func_act  unit_number  ...  variance       l_b       r_b\n",
              "0   SimpleRNN     tanh         10.0  ...  0.000072  0.043476  0.062878\n",
              "1   SimpleRNN     tanh         20.0  ...  0.000063  0.046104  0.063710\n",
              "2   SimpleRNN  sigmoid         10.0  ...  0.000022  0.043306  0.054085\n",
              "3   SimpleRNN  sigmoid         20.0  ...  0.000057  0.041452  0.058340\n",
              "4        LSTM     tanh         10.0  ...  0.000104  0.040129  0.063483\n",
              "5        LSTM     tanh         20.0  ...  0.000194  0.040450  0.072787\n",
              "6        LSTM  sigmoid         10.0  ...  0.000012  0.043930  0.051475\n",
              "7        LSTM  sigmoid         20.0  ...  0.000020  0.043646  0.053707\n",
              "8         GRU     tanh         10.0  ...  0.000111  0.044421  0.068854\n",
              "9         GRU     tanh         20.0  ...  0.000057  0.054974  0.072579\n",
              "10        GRU  sigmoid         10.0  ...  0.000023  0.041358  0.051059\n",
              "11        GRU  sigmoid         20.0  ...  0.000083  0.037954  0.059153\n",
              "\n",
              "[12 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qLagXcp8rT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "472f14cb-5504-4785-d168-26b8aed17304"
      },
      "source": [
        "summary_data.sort_values('mean_val_accuracy', ascending=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>layers</th>\n",
              "      <th>func_act</th>\n",
              "      <th>unit_number</th>\n",
              "      <th>mean_train_accuracy</th>\n",
              "      <th>mean_val_accuracy</th>\n",
              "      <th>variance</th>\n",
              "      <th>l_b</th>\n",
              "      <th>r_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GRU</td>\n",
              "      <td>tanh</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.072046</td>\n",
              "      <td>0.064044</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.054974</td>\n",
              "      <td>0.072579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.073811</td>\n",
              "      <td>0.056354</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.046104</td>\n",
              "      <td>0.063710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GRU</td>\n",
              "      <td>tanh</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.057983</td>\n",
              "      <td>0.056102</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.044421</td>\n",
              "      <td>0.068854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>tanh</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.057479</td>\n",
              "      <td>0.055976</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.040450</td>\n",
              "      <td>0.072787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>tanh</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.052812</td>\n",
              "      <td>0.052824</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.040129</td>\n",
              "      <td>0.063483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.064794</td>\n",
              "      <td>0.052320</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.043476</td>\n",
              "      <td>0.062878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.049187</td>\n",
              "      <td>0.048664</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.041452</td>\n",
              "      <td>0.058340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>GRU</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.049060</td>\n",
              "      <td>0.048285</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.037954</td>\n",
              "      <td>0.059153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.047894</td>\n",
              "      <td>0.048159</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.043306</td>\n",
              "      <td>0.054085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.047358</td>\n",
              "      <td>0.048033</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.043646</td>\n",
              "      <td>0.053707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GRU</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.050006</td>\n",
              "      <td>0.047655</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.041358</td>\n",
              "      <td>0.051059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.046853</td>\n",
              "      <td>0.046899</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.043930</td>\n",
              "      <td>0.051475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       layers func_act  unit_number  ...  variance       l_b       r_b\n",
              "9         GRU     tanh         20.0  ...  0.000057  0.054974  0.072579\n",
              "1   SimpleRNN     tanh         20.0  ...  0.000063  0.046104  0.063710\n",
              "8         GRU     tanh         10.0  ...  0.000111  0.044421  0.068854\n",
              "5        LSTM     tanh         20.0  ...  0.000194  0.040450  0.072787\n",
              "4        LSTM     tanh         10.0  ...  0.000104  0.040129  0.063483\n",
              "0   SimpleRNN     tanh         10.0  ...  0.000072  0.043476  0.062878\n",
              "3   SimpleRNN  sigmoid         20.0  ...  0.000057  0.041452  0.058340\n",
              "11        GRU  sigmoid         20.0  ...  0.000083  0.037954  0.059153\n",
              "2   SimpleRNN  sigmoid         10.0  ...  0.000022  0.043306  0.054085\n",
              "7        LSTM  sigmoid         20.0  ...  0.000020  0.043646  0.053707\n",
              "10        GRU  sigmoid         10.0  ...  0.000023  0.041358  0.051059\n",
              "6        LSTM  sigmoid         10.0  ...  0.000012  0.043930  0.051475\n",
              "\n",
              "[12 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhbNxjPh8wBL",
        "colab_type": "text"
      },
      "source": [
        "# Выводы\n",
        "Можно сделть вывод, что применение функции активации tanh, а также применение более длинных цепочек способствует повышению значения метрики на valid выборках. Однако, большая вычислительная сложность эксперимента привела к критическому сокращению количества эпох и итераций. Для получения более репрезентативных результатов необходимо проводить более объёмное исследование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlvQNKwkuk32",
        "colab_type": "text"
      },
      "source": [
        "## Задание 2\n",
        "\n",
        "Попробуйте на numpy реализовать нейронную сеть архитектуры LSTM\n",
        "\n",
        "Реализация (как есть из книги Э.Траска \"GrokkingDeepLearning\")\n",
        "\n",
        "Рассматривется пример создния фреймворка с ключевыми слоями для демонстрации автоматизации обратного распрострнения. Данный фреймворк включает в себя класс, реализующий рекурентную ячейку и её развитие - LSTM слой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD6GcPrYuhF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tensor (object):\n",
        "    \n",
        "    def __init__(self,data,\n",
        "                 autograd=False,\n",
        "                 creators=None,\n",
        "                 creation_op=None,\n",
        "                 id=None):\n",
        "        \n",
        "        self.data = np.array(data)\n",
        "        self.autograd = autograd\n",
        "        self.grad = None\n",
        "\n",
        "        if(id is None):\n",
        "            self.id = np.random.randint(0,1000000000)\n",
        "        else:\n",
        "            self.id = id\n",
        "        \n",
        "        self.creators = creators\n",
        "        self.creation_op = creation_op\n",
        "        self.children = {}\n",
        "        \n",
        "        if(creators is not None):\n",
        "            for c in creators:\n",
        "                if(self.id not in c.children):\n",
        "                    c.children[self.id] = 1\n",
        "                else:\n",
        "                    c.children[self.id] += 1\n",
        "\n",
        "    def all_children_grads_accounted_for(self):\n",
        "        for id,cnt in self.children.items():\n",
        "            if(cnt != 0):\n",
        "                return False\n",
        "        return True \n",
        "        \n",
        "    def backward(self,grad=None, grad_origin=None):\n",
        "        if(self.autograd):\n",
        " \n",
        "            if(grad is None):\n",
        "                grad = Tensor(np.ones_like(self.data))\n",
        "\n",
        "            if(grad_origin is not None):\n",
        "                if(self.children[grad_origin.id] == 0):\n",
        "                    return\n",
        "                    print(self.id)\n",
        "                    print(self.creation_op)\n",
        "                    print(len(self.creators))\n",
        "                    for c in self.creators:\n",
        "                        print(c.creation_op)\n",
        "                    raise Exception(\"cannot backprop more than once\")\n",
        "                else:\n",
        "                    self.children[grad_origin.id] -= 1\n",
        "\n",
        "            if(self.grad is None):\n",
        "                self.grad = grad\n",
        "            else:\n",
        "                self.grad += grad\n",
        "            \n",
        "            # grads must not have grads of their own\n",
        "            assert grad.autograd == False\n",
        "            \n",
        "            # only continue backpropping if there's something to\n",
        "            # backprop into and if all gradients (from children)\n",
        "            # are accounted for override waiting for children if\n",
        "            # \"backprop\" was called on this variable directly\n",
        "            if(self.creators is not None and \n",
        "               (self.all_children_grads_accounted_for() or \n",
        "                grad_origin is None)):\n",
        "\n",
        "                if(self.creation_op == \"add\"):\n",
        "                    self.creators[0].backward(self.grad, self)\n",
        "                    self.creators[1].backward(self.grad, self)\n",
        "                    \n",
        "                if(self.creation_op == \"sub\"):\n",
        "                    self.creators[0].backward(Tensor(self.grad.data), self)\n",
        "                    self.creators[1].backward(Tensor(self.grad.__neg__().data), self)\n",
        "\n",
        "                if(self.creation_op == \"mul\"):\n",
        "                    new = self.grad * self.creators[1]\n",
        "                    self.creators[0].backward(new , self)\n",
        "                    new = self.grad * self.creators[0]\n",
        "                    self.creators[1].backward(new, self)                    \n",
        "                    \n",
        "                if(self.creation_op == \"mm\"):\n",
        "                    c0 = self.creators[0]\n",
        "                    c1 = self.creators[1]\n",
        "                    new = self.grad.mm(c1.transpose())\n",
        "                    c0.backward(new)\n",
        "                    new = self.grad.transpose().mm(c0).transpose()\n",
        "                    c1.backward(new)\n",
        "                    \n",
        "                if(self.creation_op == \"transpose\"):\n",
        "                    self.creators[0].backward(self.grad.transpose())\n",
        "\n",
        "                if(\"sum\" in self.creation_op):\n",
        "                    dim = int(self.creation_op.split(\"_\")[1])\n",
        "                    self.creators[0].backward(self.grad.expand(dim,\n",
        "                                                               self.creators[0].data.shape[dim]))\n",
        "\n",
        "                if(\"expand\" in self.creation_op):\n",
        "                    dim = int(self.creation_op.split(\"_\")[1])\n",
        "                    self.creators[0].backward(self.grad.sum(dim))\n",
        "                    \n",
        "                if(self.creation_op == \"neg\"):\n",
        "                    self.creators[0].backward(self.grad.__neg__())\n",
        "                    \n",
        "                if(self.creation_op == \"sigmoid\"):\n",
        "                    ones = Tensor(np.ones_like(self.grad.data))\n",
        "                    self.creators[0].backward(self.grad * (self * (ones - self)))\n",
        "                \n",
        "                if(self.creation_op == \"tanh\"):\n",
        "                    ones = Tensor(np.ones_like(self.grad.data))\n",
        "                    self.creators[0].backward(self.grad * (ones - (self * self)))\n",
        "                \n",
        "                if(self.creation_op == \"index_select\"):\n",
        "                    new_grad = np.zeros_like(self.creators[0].data)\n",
        "                    indices_ = self.index_select_indices.data.flatten()\n",
        "                    grad_ = grad.data.reshape(len(indices_), -1)\n",
        "                    for i in range(len(indices_)):\n",
        "                        new_grad[indices_[i]] += grad_[i]\n",
        "                    self.creators[0].backward(Tensor(new_grad))\n",
        "                    \n",
        "                if(self.creation_op == \"cross_entropy\"):\n",
        "                    dx = self.softmax_output - self.target_dist\n",
        "                    self.creators[0].backward(Tensor(dx))\n",
        "                    \n",
        "    def __add__(self, other):\n",
        "        if(self.autograd and other.autograd):\n",
        "            return Tensor(self.data + other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"add\")\n",
        "        return Tensor(self.data + other.data)\n",
        "\n",
        "    def __neg__(self):\n",
        "        if(self.autograd):\n",
        "            return Tensor(self.data * -1,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"neg\")\n",
        "        return Tensor(self.data * -1)\n",
        "    \n",
        "    def __sub__(self, other):\n",
        "        if(self.autograd and other.autograd):\n",
        "            return Tensor(self.data - other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"sub\")\n",
        "        return Tensor(self.data - other.data)\n",
        "    \n",
        "    def __mul__(self, other):\n",
        "        if(self.autograd and other.autograd):\n",
        "            return Tensor(self.data * other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"mul\")\n",
        "        return Tensor(self.data * other.data)    \n",
        "\n",
        "    def sum(self, dim):\n",
        "        if(self.autograd):\n",
        "            return Tensor(self.data.sum(dim),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"sum_\"+str(dim))\n",
        "        return Tensor(self.data.sum(dim))\n",
        "    \n",
        "    def expand(self, dim,copies):\n",
        "\n",
        "        trans_cmd = list(range(0,len(self.data.shape)))\n",
        "        trans_cmd.insert(dim,len(self.data.shape))\n",
        "        new_data = self.data.repeat(copies).reshape(list(self.data.shape) + [copies]).transpose(trans_cmd)\n",
        "        \n",
        "        if(self.autograd):\n",
        "            return Tensor(new_data,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"expand_\"+str(dim))\n",
        "        return Tensor(new_data)\n",
        "    \n",
        "    def transpose(self):\n",
        "        if(self.autograd):\n",
        "            return Tensor(self.data.transpose(),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"transpose\")\n",
        "        \n",
        "        return Tensor(self.data.transpose())\n",
        "    \n",
        "    def mm(self, x):\n",
        "        if(self.autograd):\n",
        "            return Tensor(self.data.dot(x.data),\n",
        "                          autograd=True,\n",
        "                          creators=[self,x],\n",
        "                          creation_op=\"mm\")\n",
        "        return Tensor(self.data.dot(x.data))\n",
        "    \n",
        "    def sigmoid(self):\n",
        "        if(self.autograd):\n",
        "            return Tensor(1 / (1 + np.exp(-self.data)),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"sigmoid\")\n",
        "        return Tensor(1 / (1 + np.exp(-self.data)))\n",
        "\n",
        "    def tanh(self):\n",
        "        if(self.autograd):\n",
        "            return Tensor(np.tanh(self.data),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"tanh\")\n",
        "        return Tensor(np.tanh(self.data))\n",
        "    \n",
        "    def index_select(self, indices):\n",
        "\n",
        "        if(self.autograd):\n",
        "            new = Tensor(self.data[indices.data],\n",
        "                         autograd=True,\n",
        "                         creators=[self],\n",
        "                         creation_op=\"index_select\")\n",
        "            new.index_select_indices = indices\n",
        "            return new\n",
        "        return Tensor(self.data[indices.data])\n",
        "    \n",
        "    def softmax(self):\n",
        "        temp = np.exp(self.data)\n",
        "        softmax_output = temp / np.sum(temp,\n",
        "                                       axis=len(self.data.shape)-1,\n",
        "                                       keepdims=True)\n",
        "        return softmax_output\n",
        "    \n",
        "    def cross_entropy(self, target_indices):\n",
        "\n",
        "        temp = np.exp(self.data)\n",
        "        softmax_output = temp / np.sum(temp,\n",
        "                                       axis=len(self.data.shape)-1,\n",
        "                                       keepdims=True)\n",
        "        \n",
        "        t = target_indices.data.flatten()\n",
        "        p = softmax_output.reshape(len(t),-1)\n",
        "        target_dist = np.eye(p.shape[1])[t]\n",
        "        loss = -(np.log(p) * (target_dist)).sum(1).mean()\n",
        "    \n",
        "        if(self.autograd):\n",
        "            out = Tensor(loss,\n",
        "                         autograd=True,\n",
        "                         creators=[self],\n",
        "                         creation_op=\"cross_entropy\")\n",
        "            out.softmax_output = softmax_output\n",
        "            out.target_dist = target_dist\n",
        "            return out\n",
        "\n",
        "        return Tensor(loss)\n",
        "        \n",
        "    \n",
        "    def __repr__(self):\n",
        "        return str(self.data.__repr__())\n",
        "    \n",
        "    def __str__(self):\n",
        "        return str(self.data.__str__())  \n",
        "\n",
        "class Layer(object):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.parameters = list()\n",
        "        \n",
        "    def get_parameters(self):\n",
        "        return self.parameters\n",
        "\n",
        "    \n",
        "class SGD(object):\n",
        "    \n",
        "    def __init__(self, parameters, alpha=0.1):\n",
        "        self.parameters = parameters\n",
        "        self.alpha = alpha\n",
        "    \n",
        "    def zero(self):\n",
        "        for p in self.parameters:\n",
        "            p.grad.data *= 0\n",
        "        \n",
        "    def step(self, zero=True):\n",
        "        \n",
        "        for p in self.parameters:\n",
        "            \n",
        "            p.data -= p.grad.data * self.alpha\n",
        "            \n",
        "            if(zero):\n",
        "                p.grad.data *= 0\n",
        "\n",
        "\n",
        "class Linear(Layer):\n",
        "\n",
        "    def __init__(self, n_inputs, n_outputs, bias=True):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.use_bias = bias\n",
        "        \n",
        "        W = np.random.randn(n_inputs, n_outputs) * np.sqrt(2.0/(n_inputs))\n",
        "        self.weight = Tensor(W, autograd=True)\n",
        "        if(self.use_bias):\n",
        "            self.bias = Tensor(np.zeros(n_outputs), autograd=True)\n",
        "        \n",
        "        self.parameters.append(self.weight)\n",
        "        \n",
        "        if(self.use_bias):        \n",
        "            self.parameters.append(self.bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        if(self.use_bias):\n",
        "            return input.mm(self.weight)+self.bias.expand(0,len(input.data))\n",
        "        return input.mm(self.weight)\n",
        "\n",
        "\n",
        "class Sequential(Layer):\n",
        "    \n",
        "    def __init__(self, layers=list()):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layers = layers\n",
        "    \n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        for layer in self.layers:\n",
        "            input = layer.forward(input)\n",
        "        return input\n",
        "    \n",
        "    def get_parameters(self):\n",
        "        params = list()\n",
        "        for l in self.layers:\n",
        "            params += l.get_parameters()\n",
        "        return params\n",
        "\n",
        "\n",
        "class Embedding(Layer):\n",
        "    \n",
        "    def __init__(self, vocab_size, dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.dim = dim\n",
        "        \n",
        "        # this random initialiation style is just a convention from word2vec\n",
        "        self.weight = Tensor((np.random.rand(vocab_size, dim) - 0.5) / dim, autograd=True)\n",
        "        \n",
        "        self.parameters.append(self.weight)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return self.weight.index_select(input)\n",
        "\n",
        "\n",
        "class Tanh(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return input.tanh()\n",
        "\n",
        "\n",
        "class Sigmoid(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return input.sigmoid()\n",
        "    \n",
        "\n",
        "class CrossEntropyLoss(object):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, input, target):\n",
        "        return input.cross_entropy(target)\n",
        "\n",
        "    \n",
        "class RNNCell(Layer):\n",
        "    \n",
        "    def __init__(self, n_inputs, n_hidden, n_output, activation='sigmoid'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_output = n_output\n",
        "        \n",
        "        if(activation == 'sigmoid'):\n",
        "            self.activation = Sigmoid()\n",
        "        elif(activation == 'tanh'):\n",
        "            self.activation == Tanh()\n",
        "        else:\n",
        "            raise Exception(\"Non-linearity not found\")\n",
        "\n",
        "        self.w_ih = Linear(n_inputs, n_hidden)\n",
        "        self.w_hh = Linear(n_hidden, n_hidden)\n",
        "        self.w_ho = Linear(n_hidden, n_output)\n",
        "        \n",
        "        self.parameters += self.w_ih.get_parameters()\n",
        "        self.parameters += self.w_hh.get_parameters()\n",
        "        self.parameters += self.w_ho.get_parameters()        \n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        from_prev_hidden = self.w_hh.forward(hidden)\n",
        "        combined = self.w_ih.forward(input) + from_prev_hidden\n",
        "        new_hidden = self.activation.forward(combined)\n",
        "        output = self.w_ho.forward(new_hidden)\n",
        "        return output, new_hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size=1):\n",
        "        return Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)\n",
        "    \n",
        "class LSTMCell(Layer):\n",
        "    \n",
        "    def __init__(self, n_inputs, n_hidden, n_output):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_output = n_output\n",
        "\n",
        "        self.xf = Linear(n_inputs, n_hidden)\n",
        "        self.xi = Linear(n_inputs, n_hidden)\n",
        "        self.xo = Linear(n_inputs, n_hidden)        \n",
        "        self.xc = Linear(n_inputs, n_hidden)        \n",
        "        \n",
        "        self.hf = Linear(n_hidden, n_hidden, bias=False)\n",
        "        self.hi = Linear(n_hidden, n_hidden, bias=False)\n",
        "        self.ho = Linear(n_hidden, n_hidden, bias=False)\n",
        "        self.hc = Linear(n_hidden, n_hidden, bias=False)        \n",
        "        \n",
        "        self.w_ho = Linear(n_hidden, n_output, bias=False)\n",
        "        \n",
        "        self.parameters += self.xf.get_parameters()\n",
        "        self.parameters += self.xi.get_parameters()\n",
        "        self.parameters += self.xo.get_parameters()\n",
        "        self.parameters += self.xc.get_parameters()\n",
        "\n",
        "        self.parameters += self.hf.get_parameters()\n",
        "        self.parameters += self.hi.get_parameters()        \n",
        "        self.parameters += self.ho.get_parameters()        \n",
        "        self.parameters += self.hc.get_parameters()                \n",
        "        \n",
        "        self.parameters += self.w_ho.get_parameters()        \n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        \n",
        "        prev_hidden = hidden[0]        \n",
        "        prev_cell = hidden[1]\n",
        "        \n",
        "        f = (self.xf.forward(input) + self.hf.forward(prev_hidden)).sigmoid()\n",
        "        i = (self.xi.forward(input) + self.hi.forward(prev_hidden)).sigmoid()\n",
        "        o = (self.xo.forward(input) + self.ho.forward(prev_hidden)).sigmoid()        \n",
        "        g = (self.xc.forward(input) + self.hc.forward(prev_hidden)).tanh()        \n",
        "        \n",
        "        c = (f * prev_cell) + (i * g)\n",
        "        h = o * c.tanh()\n",
        "        \n",
        "        output = self.w_ho.forward(h)\n",
        "        return output, (h, c)\n",
        "    \n",
        "    def init_hidden(self, batch_size=1):\n",
        "        init_hidden = Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)\n",
        "        init_cell = Tensor(np.zeros((batch_size,self.n_hidden)), autograd=True)\n",
        "        init_hidden.data[:,0] += 1\n",
        "        init_cell.data[:,0] += 1\n",
        "        return (init_hidden, init_cell)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44o9z7x_-VBV",
        "colab_type": "text"
      },
      "source": [
        "Ячейка LSTM имеет два вектора со скрытым состоянием: h (от англ. hidden — скрытый) и cell.\n",
        "\n",
        "    c = (f * prev_cell) + (i * g)\n",
        "    h = o * c.tanh()\n",
        "\n",
        "В векторе cell каждое новое значение является суммой предыдущего значения и приращения и, взвешенных весами f и i. Здесь f — это «забывающий» («forget») вентиль (фильтр). Если этот вес получит значение 0, новая ячейка «забудет» то, что видела прежде. Если i получит значение 1, приращение и будет полностью добавлено в новую ячейку. Переменная о — это выходной вентиль (фильтр), который определяет, какая доля состояния ячейки попадет в прогноз. Например, если все значения в о равны нулю, тогда строка self.w_ho.forward(h) вернет прогноз, полностью игнорируя состояние ячейки.\n",
        "\n",
        "Три вентиля — f, i, о — и вектор приращений ячейки и; их можно представить как механизмы управления забыванием (forget), вводом (input), выводом (output) и изменением (update) соответственно. Они действуют вместе и гарантируют, что для корректировки информации, хранящейся в с, не потребуется применять матричное умножение или нелинейную функцию активации. Иначе говоря, избавляют от необходимости вызывать nonlinearity(c) или с. dot (weights).\n",
        "\n",
        "Такой подход позволяет модели LSTM сохранять информацию на протяжении\n",
        "временной последовательности, не беспокоясь о затухании или взрывном росте\n",
        "градиентов. Каждый шаг заключается в копировании (если f имеет ненулевое\n",
        "значение) и прибавлении приращения (если i имеет ненулевое значение).\n",
        "Скрытое значение h — это замаскированная версия ячейки, используемая для\n",
        "получения прогноза.\n",
        "\n",
        "Все три вентиля формируются совершенно одинаково. Они имеют свои весовые матрицы, но каждый зависит от входных значений и скрытого состояния, пропущенных через функцию sigmoid. Именно эта нелинейная функция sigmoid делает их полезными в качестве вентилей, преобразуя в диапазон от 0 до 1:\n",
        "\n",
        "    f = (self,xf.forward(input) + self.hf.forward(prev_hidden)).sigmoid()\n",
        "    i = (self.xi.forward(input) + self.hi.forward(prev_hidden)).sigmoid()\n",
        "    о = (self.xo.forward(input) + self.ho.forward(prev_hidden)).sigmoid()\n",
        "\n",
        "Вектор h все еще подвержен эффекту затухания и взрывного роста градиентов, потому что фактически используется так же, как в простой рекуррентной нейронной сети. Во-первых, поскольку вектор h всегда создается из комбинации векторов, которые сжимаются с помощью tanh и sigmoid, эффект взрывного роста градиентов на самом деле отсутствует — проявляется только эффект затухания. Но в итоге в этом нет ничего страшного, потому что h зависит от ячейки с, которая может переносить информацию на дальние расстояния: ту информацию, которую затухающие градиенты не способны переносить. То есть вся перспективная информация транспортируется с помощью с, a h — это всего лишь локальная интерпретация с, удобная для получения прогноза на выходе и активации вентилей на следующем шаге. Проще говоря, способность с переносить информацию на большие расстояния нивелирует неспособность h к тому же самому."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWzWqUILimP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys,random,math\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# dataset from http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "f = open('shakespear.txt','r')\n",
        "raw = f.read()\n",
        "f.close()\n",
        "\n",
        "vocab = list(set(raw))\n",
        "word2index = {}\n",
        "for i,word in enumerate(vocab):\n",
        "    word2index[word]=i\n",
        "indices = np.array(list(map(lambda x:word2index[x], raw)))\n",
        "\n",
        "embed = Embedding(vocab_size=len(vocab),dim=512)\n",
        "model = LSTMCell(n_inputs=512, n_hidden=512, n_output=len(vocab))\n",
        "model.w_ho.weight.data *= 0\n",
        "\n",
        "criterion = CrossEntropyLoss()\n",
        "optim = SGD(parameters=model.get_parameters() + embed.get_parameters(), alpha=0.05)\n",
        "\n",
        "batch_size = 16\n",
        "bptt = 25\n",
        "n_batches = int((indices.shape[0] / (batch_size)))\n",
        "\n",
        "trimmed_indices = indices[:n_batches*batch_size]\n",
        "batched_indices = trimmed_indices.reshape(batch_size, n_batches).transpose()\n",
        "\n",
        "input_batched_indices = batched_indices[0:-1]\n",
        "target_batched_indices = batched_indices[1:]\n",
        "\n",
        "n_bptt = int(((n_batches-1) / bptt))\n",
        "input_batches = input_batched_indices[:n_bptt*bptt].reshape(n_bptt,bptt,batch_size)\n",
        "target_batches = target_batched_indices[:n_bptt*bptt].reshape(n_bptt, bptt, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLVNHKy4j4H3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a2216409-a729-4d94-e421-5603bb2a9aa7"
      },
      "source": [
        "raw[0:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'That, poor contempt,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeAjjVjgj_Nu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e896dee-a4a0-4ce0-c55b-a4516f1cd76e"
      },
      "source": [
        "indices[0:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18,  9, 16, 54, 41, 39, 14, 60, 60, 11, 39, 56, 60,  3, 54, 45, 47,\n",
              "       14, 54, 41])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr2KS3YlkFeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3ce7e1e3-0570-4fa3-d2dc-a2cf01b05565"
      },
      "source": [
        "batched_indices[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18,  5, 45, 21, 39, 45,  7, 36, 27, 33, 18, 42, 36, 48, 36, 54],\n",
              "       [ 9, 26, 39, 60, 43, 39, 60, 36, 54, 39, 55, 39, 36, 39, 39,  9],\n",
              "       [16, 18, 43, 54, 45, 54, 11, 39, 39,  9, 29, 45, 39, 54, 21, 23],\n",
              "       [54, 28, 28, 26, 36,  9, 54, 16, 28, 16, 44,  4,  9,  9, 45,  5],\n",
              "       [41, 50, 36, 50, 36, 28, 45, 36, 54,  4,  5, 45, 28, 45, 22,  5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIboOd_8kFlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7f318cbb-4014-411f-84dd-65d23c3b56fa"
      },
      "source": [
        "input_batches[0][0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18,  5, 45, 21, 39, 45,  7, 36, 27, 33, 18, 42, 36, 48, 36, 54],\n",
              "       [ 9, 26, 39, 60, 43, 39, 60, 36, 54, 39, 55, 39, 36, 39, 39,  9],\n",
              "       [16, 18, 43, 54, 45, 54, 11, 39, 39,  9, 29, 45, 39, 54, 21, 23],\n",
              "       [54, 28, 28, 26, 36,  9, 54, 16, 28, 16, 44,  4,  9,  9, 45,  5],\n",
              "       [41, 50, 36, 50, 36, 28, 45, 36, 54,  4,  5, 45, 28, 45, 22,  5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvaVKNyakGCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a6c21786-058f-460d-dd1d-7e57aee7ac3f"
      },
      "source": [
        "target_batches[0][0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9, 26, 39, 60, 43, 39, 60, 36, 54, 39, 55, 39, 36, 39, 39,  9],\n",
              "       [16, 18, 43, 54, 45, 54, 11, 39, 39,  9, 29, 45, 39, 54, 21, 23],\n",
              "       [54, 28, 28, 26, 36,  9, 54, 16, 28, 16, 44,  4,  9,  9, 45,  5],\n",
              "       [41, 50, 36, 50, 36, 28, 45, 36, 54,  4,  5, 45, 28, 45, 22,  5],\n",
              "       [39, 39, 36, 39, 41,  3, 11, 36, 39, 45, 53, 11, 47, 47, 39, 35]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvlgZb2isUSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(n=30, init_char=' '):\n",
        "    s = \"\"\n",
        "    hidden = model.init_hidden(batch_size=1)\n",
        "    input = Tensor(np.array([word2index[init_char]]))\n",
        "    for i in range(n):\n",
        "        rnn_input = embed.forward(input)\n",
        "        output, hidden = model.forward(input=rnn_input, hidden=hidden)\n",
        "#         output.data *= 25\n",
        "#         temp_dist = output.softmax()\n",
        "#         temp_dist /= temp_dist.sum()\n",
        "\n",
        "#         m = (temp_dist > np.random.rand()).argmax()\n",
        "        m = output.data.argmax()\n",
        "        c = vocab[m]\n",
        "        input = Tensor(np.array([m]))\n",
        "        s += c\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7F9S8b2xf81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcd2dc96-6d2c-4204-992c-1b3498741ed0"
      },
      "source": [
        "min_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-QdSVM1kVpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(iterations=400):\n",
        "    min_loss = 1000\n",
        "    for iter in range(iterations):\n",
        "        total_loss = 0\n",
        "        n_loss = 0\n",
        "\n",
        "        hidden = model.init_hidden(batch_size=batch_size)\n",
        "        batches_to_train = len(input_batches)\n",
        "    #     batches_to_train = 32\n",
        "        for batch_i in range(batches_to_train):\n",
        "\n",
        "            hidden = (Tensor(hidden[0].data, autograd=True), Tensor(hidden[1].data, autograd=True))\n",
        "\n",
        "            losses = list()\n",
        "            for t in range(bptt):\n",
        "                input = Tensor(input_batches[batch_i][t], autograd=True)\n",
        "                rnn_input = embed.forward(input=input)\n",
        "                output, hidden = model.forward(input=rnn_input, hidden=hidden)\n",
        "\n",
        "                target = Tensor(target_batches[batch_i][t], autograd=True)    \n",
        "                batch_loss = criterion.forward(output, target)\n",
        "\n",
        "                if(t == 0):\n",
        "                    losses.append(batch_loss)\n",
        "                else:\n",
        "                    losses.append(batch_loss + losses[-1])\n",
        "\n",
        "            loss = losses[-1]\n",
        "\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total_loss += loss.data / bptt\n",
        "\n",
        "            epoch_loss = np.exp(total_loss / (batch_i+1))\n",
        "            if(epoch_loss < min_loss):\n",
        "                min_loss = epoch_loss\n",
        "                print()\n",
        "\n",
        "            log = \"\\r Iter:\" + str(iter)\n",
        "            log += \" - Alpha:\" + str(optim.alpha)[0:5]\n",
        "            log += \" - Batch \"+str(batch_i+1)+\"/\"+str(len(input_batches))\n",
        "            log += \" - Min Loss:\" + str(min_loss)[0:5]\n",
        "            log += \" - Loss:\" + str(epoch_loss)\n",
        "            if(batch_i == 0):\n",
        "                log += \" - \" + generate_sample(n=70, init_char='T').replace(\"\\n\",\" \")\n",
        "            if(batch_i % 1 == 0):\n",
        "                sys.stdout.write(log)\n",
        "        optim.alpha *= 0.99"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XRt9BBRkVlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5a1f868-571d-415b-b2c4-7eefb9c8bd88"
      },
      "source": [
        "train(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Iter:0 - Alpha:0.05 - Batch 2/249 - Min Loss:61.43 - Loss:61.50395764660655\n",
            " Iter:0 - Alpha:0.05 - Batch 3/249 - Min Loss:61.37 - Loss:61.3736297066837\n",
            " Iter:0 - Alpha:0.05 - Batch 4/249 - Min Loss:61.01 - Loss:61.01063938517639\n",
            " Iter:0 - Alpha:0.05 - Batch 5/249 - Min Loss:60.26 - Loss:60.269906839785314\n",
            " Iter:0 - Alpha:0.05 - Batch 6/249 - Min Loss:58.84 - Loss:58.84148621314299\n",
            " Iter:0 - Alpha:0.05 - Batch 7/249 - Min Loss:56.63 - Loss:56.63600933131954\n",
            " Iter:0 - Alpha:0.05 - Batch 8/249 - Min Loss:52.68 - Loss:52.68878864926658\n",
            " Iter:0 - Alpha:0.05 - Batch 9/249 - Min Loss:48.72 - Loss:48.72161564909471\n",
            " Iter:0 - Alpha:0.05 - Batch 10/249 - Min Loss:47.19 - Loss:47.19780782601813\n",
            " Iter:0 - Alpha:0.05 - Batch 11/249 - Min Loss:45.42 - Loss:45.424298950589794\n",
            " Iter:0 - Alpha:0.05 - Batch 12/249 - Min Loss:44.09 - Loss:44.092127806603465\n",
            " Iter:0 - Alpha:0.05 - Batch 13/249 - Min Loss:42.96 - Loss:42.964972808747774\n",
            " Iter:0 - Alpha:0.05 - Batch 14/249 - Min Loss:42.45 - Loss:42.452142062204736\n",
            " Iter:0 - Alpha:0.05 - Batch 15/249 - Min Loss:41.48 - Loss:41.48431400356398\n",
            " Iter:0 - Alpha:0.05 - Batch 16/249 - Min Loss:40.50 - Loss:40.50924532086388\n",
            " Iter:0 - Alpha:0.05 - Batch 17/249 - Min Loss:39.58 - Loss:39.58915875107085\n",
            " Iter:0 - Alpha:0.05 - Batch 18/249 - Min Loss:38.97 - Loss:38.970322640510446\n",
            " Iter:0 - Alpha:0.05 - Batch 19/249 - Min Loss:38.46 - Loss:38.468387759717736\n",
            " Iter:0 - Alpha:0.05 - Batch 20/249 - Min Loss:37.82 - Loss:37.82517071548089\n",
            " Iter:0 - Alpha:0.05 - Batch 24/249 - Min Loss:37.10 - Loss:37.17720974581725\n",
            " Iter:0 - Alpha:0.05 - Batch 25/249 - Min Loss:36.65 - Loss:36.655511668790254\n",
            " Iter:0 - Alpha:0.05 - Batch 26/249 - Min Loss:35.97 - Loss:35.97926856959905\n",
            " Iter:0 - Alpha:0.05 - Batch 27/249 - Min Loss:35.61 - Loss:35.614751188740904\n",
            " Iter:0 - Alpha:0.05 - Batch 28/249 - Min Loss:35.12 - Loss:35.12068600176885\n",
            " Iter:0 - Alpha:0.05 - Batch 29/249 - Min Loss:34.75 - Loss:34.756401858629374\n",
            " Iter:0 - Alpha:0.05 - Batch 30/249 - Min Loss:34.38 - Loss:34.38217397224482\n",
            " Iter:0 - Alpha:0.05 - Batch 31/249 - Min Loss:34.15 - Loss:34.15687092232486\n",
            " Iter:0 - Alpha:0.05 - Batch 32/249 - Min Loss:33.83 - Loss:33.83917491964368\n",
            " Iter:0 - Alpha:0.05 - Batch 33/249 - Min Loss:33.54 - Loss:33.54578750229636\n",
            " Iter:0 - Alpha:0.05 - Batch 34/249 - Min Loss:33.23 - Loss:33.23917319647738\n",
            " Iter:0 - Alpha:0.05 - Batch 35/249 - Min Loss:33.11 - Loss:33.11306188189393\n",
            " Iter:0 - Alpha:0.05 - Batch 36/249 - Min Loss:32.95 - Loss:32.9565190178945\n",
            " Iter:0 - Alpha:0.05 - Batch 37/249 - Min Loss:32.70 - Loss:32.703952406226485\n",
            " Iter:0 - Alpha:0.05 - Batch 38/249 - Min Loss:32.48 - Loss:32.487131347122826\n",
            " Iter:0 - Alpha:0.05 - Batch 39/249 - Min Loss:32.38 - Loss:32.3892572555698\n",
            " Iter:0 - Alpha:0.05 - Batch 40/249 - Min Loss:32.10 - Loss:32.10469888218284\n",
            " Iter:0 - Alpha:0.05 - Batch 41/249 - Min Loss:31.99 - Loss:31.995434414796595\n",
            " Iter:0 - Alpha:0.05 - Batch 42/249 - Min Loss:31.85 - Loss:31.850105585470008\n",
            " Iter:0 - Alpha:0.05 - Batch 43/249 - Min Loss:31.58 - Loss:31.581437320201267\n",
            " Iter:0 - Alpha:0.05 - Batch 49/249 - Min Loss:31.53 - Loss:31.576156241993214\n",
            " Iter:0 - Alpha:0.05 - Batch 50/249 - Min Loss:31.43 - Loss:31.43284857089971\n",
            " Iter:0 - Alpha:0.05 - Batch 51/249 - Min Loss:31.16 - Loss:31.166888288313938\n",
            " Iter:0 - Alpha:0.05 - Batch 52/249 - Min Loss:30.99 - Loss:30.998691778663854\n",
            " Iter:0 - Alpha:0.05 - Batch 53/249 - Min Loss:30.88 - Loss:30.883227710344947\n",
            " Iter:0 - Alpha:0.05 - Batch 54/249 - Min Loss:30.72 - Loss:30.724984991881747\n",
            " Iter:0 - Alpha:0.05 - Batch 55/249 - Min Loss:30.54 - Loss:30.540801487156518\n",
            " Iter:0 - Alpha:0.05 - Batch 56/249 - Min Loss:30.38 - Loss:30.38167548230328\n",
            " Iter:0 - Alpha:0.05 - Batch 57/249 - Min Loss:30.18 - Loss:30.18738075887357\n",
            " Iter:0 - Alpha:0.05 - Batch 58/249 - Min Loss:30.04 - Loss:30.04260221212051\n",
            " Iter:0 - Alpha:0.05 - Batch 59/249 - Min Loss:29.85 - Loss:29.859718838210533\n",
            " Iter:0 - Alpha:0.05 - Batch 60/249 - Min Loss:29.69 - Loss:29.697643690052878\n",
            " Iter:0 - Alpha:0.05 - Batch 61/249 - Min Loss:29.48 - Loss:29.487077121367076\n",
            " Iter:0 - Alpha:0.05 - Batch 62/249 - Min Loss:29.31 - Loss:29.317661985452627\n",
            " Iter:0 - Alpha:0.05 - Batch 63/249 - Min Loss:29.10 - Loss:29.102116794601788\n",
            " Iter:0 - Alpha:0.05 - Batch 64/249 - Min Loss:28.92 - Loss:28.92519301625896\n",
            " Iter:0 - Alpha:0.05 - Batch 65/249 - Min Loss:28.85 - Loss:28.854738760526967\n",
            " Iter:0 - Alpha:0.05 - Batch 66/249 - Min Loss:28.79 - Loss:28.796422913997525\n",
            " Iter:0 - Alpha:0.05 - Batch 67/249 - Min Loss:28.67 - Loss:28.673580536912016\n",
            " Iter:0 - Alpha:0.05 - Batch 68/249 - Min Loss:28.46 - Loss:28.469273688775967\n",
            " Iter:0 - Alpha:0.05 - Batch 69/249 - Min Loss:28.37 - Loss:28.37635597186601\n",
            " Iter:0 - Alpha:0.05 - Batch 70/249 - Min Loss:28.23 - Loss:28.234997819051564\n",
            " Iter:0 - Alpha:0.05 - Batch 71/249 - Min Loss:28.15 - Loss:28.157024162645815\n",
            " Iter:0 - Alpha:0.05 - Batch 72/249 - Min Loss:28.13 - Loss:28.1319118788434\n",
            " Iter:0 - Alpha:0.05 - Batch 73/249 - Min Loss:28.04 - Loss:28.046231689775265\n",
            " Iter:0 - Alpha:0.05 - Batch 74/249 - Min Loss:27.88 - Loss:27.882903140862176\n",
            " Iter:0 - Alpha:0.05 - Batch 75/249 - Min Loss:27.77 - Loss:27.771234207402514\n",
            " Iter:0 - Alpha:0.05 - Batch 76/249 - Min Loss:27.68 - Loss:27.6842590186696\n",
            " Iter:0 - Alpha:0.05 - Batch 77/249 - Min Loss:27.56 - Loss:27.561213154015462\n",
            " Iter:0 - Alpha:0.05 - Batch 78/249 - Min Loss:27.48 - Loss:27.48425001241434\n",
            " Iter:0 - Alpha:0.05 - Batch 79/249 - Min Loss:27.37 - Loss:27.376863085238828\n",
            " Iter:0 - Alpha:0.05 - Batch 80/249 - Min Loss:27.28 - Loss:27.28032735750375\n",
            " Iter:0 - Alpha:0.05 - Batch 81/249 - Min Loss:27.13 - Loss:27.13725100917658\n",
            " Iter:0 - Alpha:0.05 - Batch 82/249 - Min Loss:27.05 - Loss:27.057924472547636\n",
            " Iter:0 - Alpha:0.05 - Batch 83/249 - Min Loss:26.97 - Loss:26.97271846785529\n",
            " Iter:0 - Alpha:0.05 - Batch 86/249 - Min Loss:26.95 - Loss:26.976848946260414\n",
            " Iter:0 - Alpha:0.05 - Batch 87/249 - Min Loss:26.82 - Loss:26.82112088732075\n",
            " Iter:0 - Alpha:0.05 - Batch 88/249 - Min Loss:26.68 - Loss:26.68746822202644\n",
            " Iter:0 - Alpha:0.05 - Batch 89/249 - Min Loss:26.55 - Loss:26.55226667584506\n",
            " Iter:0 - Alpha:0.05 - Batch 90/249 - Min Loss:26.42 - Loss:26.429429564061913\n",
            " Iter:0 - Alpha:0.05 - Batch 91/249 - Min Loss:26.31 - Loss:26.31839626948311\n",
            " Iter:0 - Alpha:0.05 - Batch 92/249 - Min Loss:26.26 - Loss:26.26133673151034\n",
            " Iter:0 - Alpha:0.05 - Batch 93/249 - Min Loss:26.11 - Loss:26.114108576293738\n",
            " Iter:0 - Alpha:0.05 - Batch 94/249 - Min Loss:26.01 - Loss:26.011274538504733\n",
            " Iter:0 - Alpha:0.05 - Batch 95/249 - Min Loss:25.90 - Loss:25.90251528427718\n",
            " Iter:0 - Alpha:0.05 - Batch 96/249 - Min Loss:25.86 - Loss:25.868165988529636\n",
            " Iter:0 - Alpha:0.05 - Batch 97/249 - Min Loss:25.76 - Loss:25.765770677240965\n",
            " Iter:0 - Alpha:0.05 - Batch 98/249 - Min Loss:25.67 - Loss:25.670767174436097\n",
            " Iter:0 - Alpha:0.05 - Batch 99/249 - Min Loss:25.55 - Loss:25.552115616958837\n",
            " Iter:0 - Alpha:0.05 - Batch 100/249 - Min Loss:25.44 - Loss:25.445590523399726\n",
            " Iter:0 - Alpha:0.05 - Batch 101/249 - Min Loss:25.35 - Loss:25.352512459504045\n",
            " Iter:0 - Alpha:0.05 - Batch 102/249 - Min Loss:25.25 - Loss:25.252260308440345\n",
            " Iter:0 - Alpha:0.05 - Batch 103/249 - Min Loss:25.15 - Loss:25.152126768055638\n",
            " Iter:0 - Alpha:0.05 - Batch 104/249 - Min Loss:25.07 - Loss:25.07294712482244\n",
            " Iter:0 - Alpha:0.05 - Batch 105/249 - Min Loss:25.00 - Loss:25.002886129427857\n",
            " Iter:0 - Alpha:0.05 - Batch 106/249 - Min Loss:24.90 - Loss:24.904950544680208\n",
            " Iter:0 - Alpha:0.05 - Batch 107/249 - Min Loss:24.84 - Loss:24.84187443178292\n",
            " Iter:0 - Alpha:0.05 - Batch 108/249 - Min Loss:24.74 - Loss:24.74036287688322\n",
            " Iter:0 - Alpha:0.05 - Batch 109/249 - Min Loss:24.65 - Loss:24.653809294419354\n",
            " Iter:0 - Alpha:0.05 - Batch 110/249 - Min Loss:24.58 - Loss:24.582381589921074\n",
            " Iter:0 - Alpha:0.05 - Batch 111/249 - Min Loss:24.51 - Loss:24.515719488701468\n",
            " Iter:0 - Alpha:0.05 - Batch 112/249 - Min Loss:24.42 - Loss:24.428327845932554\n",
            " Iter:0 - Alpha:0.05 - Batch 113/249 - Min Loss:24.33 - Loss:24.333631880547454\n",
            " Iter:0 - Alpha:0.05 - Batch 114/249 - Min Loss:24.25 - Loss:24.258208905856208\n",
            " Iter:0 - Alpha:0.05 - Batch 115/249 - Min Loss:24.18 - Loss:24.18890226927859\n",
            " Iter:0 - Alpha:0.05 - Batch 116/249 - Min Loss:24.10 - Loss:24.106717546364337\n",
            " Iter:0 - Alpha:0.05 - Batch 117/249 - Min Loss:24.03 - Loss:24.039355420129446\n",
            " Iter:0 - Alpha:0.05 - Batch 118/249 - Min Loss:23.95 - Loss:23.952450872660858\n",
            " Iter:0 - Alpha:0.05 - Batch 119/249 - Min Loss:23.89 - Loss:23.898339419247936\n",
            " Iter:0 - Alpha:0.05 - Batch 120/249 - Min Loss:23.81 - Loss:23.814963305322117\n",
            " Iter:0 - Alpha:0.05 - Batch 121/249 - Min Loss:23.73 - Loss:23.73800473347888\n",
            " Iter:0 - Alpha:0.05 - Batch 122/249 - Min Loss:23.65 - Loss:23.650641227474683\n",
            " Iter:0 - Alpha:0.05 - Batch 123/249 - Min Loss:23.56 - Loss:23.562265506316788\n",
            " Iter:0 - Alpha:0.05 - Batch 124/249 - Min Loss:23.47 - Loss:23.478154661511002\n",
            " Iter:0 - Alpha:0.05 - Batch 125/249 - Min Loss:23.40 - Loss:23.409890165161556\n",
            " Iter:0 - Alpha:0.05 - Batch 126/249 - Min Loss:23.35 - Loss:23.352717977923994\n",
            " Iter:0 - Alpha:0.05 - Batch 127/249 - Min Loss:23.28 - Loss:23.281045965142276\n",
            " Iter:0 - Alpha:0.05 - Batch 128/249 - Min Loss:23.18 - Loss:23.186050334910192\n",
            " Iter:0 - Alpha:0.05 - Batch 129/249 - Min Loss:23.10 - Loss:23.103853989914143\n",
            " Iter:0 - Alpha:0.05 - Batch 130/249 - Min Loss:23.03 - Loss:23.03991921826136\n",
            " Iter:0 - Alpha:0.05 - Batch 131/249 - Min Loss:22.95 - Loss:22.955259208032043\n",
            " Iter:0 - Alpha:0.05 - Batch 132/249 - Min Loss:22.86 - Loss:22.867627377169626\n",
            " Iter:0 - Alpha:0.05 - Batch 133/249 - Min Loss:22.79 - Loss:22.790002743983234\n",
            " Iter:0 - Alpha:0.05 - Batch 134/249 - Min Loss:22.70 - Loss:22.708487090816703\n",
            " Iter:0 - Alpha:0.05 - Batch 136/249 - Min Loss:22.66 - Loss:22.67627254572151\n",
            " Iter:0 - Alpha:0.05 - Batch 137/249 - Min Loss:22.61 - Loss:22.611195755245177\n",
            " Iter:0 - Alpha:0.05 - Batch 138/249 - Min Loss:22.52 - Loss:22.523522151558268\n",
            " Iter:0 - Alpha:0.05 - Batch 140/249 - Min Loss:22.48 - Loss:22.501337391835772\n",
            " Iter:0 - Alpha:0.05 - Batch 141/249 - Min Loss:22.43 - Loss:22.431873187816255\n",
            " Iter:0 - Alpha:0.05 - Batch 142/249 - Min Loss:22.35 - Loss:22.351415003391324\n",
            " Iter:0 - Alpha:0.05 - Batch 143/249 - Min Loss:22.27 - Loss:22.277429461185825\n",
            " Iter:0 - Alpha:0.05 - Batch 144/249 - Min Loss:22.20 - Loss:22.20658740549601\n",
            " Iter:0 - Alpha:0.05 - Batch 146/249 - Min Loss:22.16 - Loss:22.196475495357483\n",
            " Iter:0 - Alpha:0.05 - Batch 147/249 - Min Loss:22.15 - Loss:22.151875688836512\n",
            " Iter:0 - Alpha:0.05 - Batch 148/249 - Min Loss:22.08 - Loss:22.087513119417693\n",
            " Iter:0 - Alpha:0.05 - Batch 149/249 - Min Loss:22.01 - Loss:22.017354420293348\n",
            " Iter:0 - Alpha:0.05 - Batch 150/249 - Min Loss:21.95 - Loss:21.95603542151571\n",
            " Iter:0 - Alpha:0.05 - Batch 151/249 - Min Loss:21.91 - Loss:21.917924326487388\n",
            " Iter:0 - Alpha:0.05 - Batch 152/249 - Min Loss:21.86 - Loss:21.866971333194055\n",
            " Iter:0 - Alpha:0.05 - Batch 153/249 - Min Loss:21.79 - Loss:21.792296839504843\n",
            " Iter:0 - Alpha:0.05 - Batch 154/249 - Min Loss:21.73 - Loss:21.73876423922069\n",
            " Iter:0 - Alpha:0.05 - Batch 155/249 - Min Loss:21.70 - Loss:21.70364584869217\n",
            " Iter:0 - Alpha:0.05 - Batch 156/249 - Min Loss:21.68 - Loss:21.68383628986473\n",
            " Iter:0 - Alpha:0.05 - Batch 157/249 - Min Loss:21.64 - Loss:21.640796707208718\n",
            " Iter:0 - Alpha:0.05 - Batch 158/249 - Min Loss:21.58 - Loss:21.588008599342384\n",
            " Iter:0 - Alpha:0.05 - Batch 159/249 - Min Loss:21.55 - Loss:21.552047716363198\n",
            " Iter:0 - Alpha:0.05 - Batch 160/249 - Min Loss:21.49 - Loss:21.496984007194133\n",
            " Iter:0 - Alpha:0.05 - Batch 161/249 - Min Loss:21.43 - Loss:21.43670693165273\n",
            " Iter:0 - Alpha:0.05 - Batch 162/249 - Min Loss:21.38 - Loss:21.385289127808722\n",
            " Iter:0 - Alpha:0.05 - Batch 163/249 - Min Loss:21.33 - Loss:21.331477331316115\n",
            " Iter:0 - Alpha:0.05 - Batch 164/249 - Min Loss:21.28 - Loss:21.286210318233948\n",
            " Iter:0 - Alpha:0.05 - Batch 165/249 - Min Loss:21.24 - Loss:21.242626293013938\n",
            " Iter:0 - Alpha:0.05 - Batch 166/249 - Min Loss:21.19 - Loss:21.195390598378687\n",
            " Iter:0 - Alpha:0.05 - Batch 167/249 - Min Loss:21.16 - Loss:21.165702904501373\n",
            " Iter:0 - Alpha:0.05 - Batch 168/249 - Min Loss:21.12 - Loss:21.12843732570778\n",
            " Iter:0 - Alpha:0.05 - Batch 169/249 - Min Loss:21.07 - Loss:21.076418095942092\n",
            " Iter:0 - Alpha:0.05 - Batch 170/249 - Min Loss:21.03 - Loss:21.037454755797235\n",
            " Iter:0 - Alpha:0.05 - Batch 171/249 - Min Loss:21.00 - Loss:21.004372648394206\n",
            " Iter:0 - Alpha:0.05 - Batch 172/249 - Min Loss:20.97 - Loss:20.978386049829684\n",
            " Iter:0 - Alpha:0.05 - Batch 173/249 - Min Loss:20.93 - Loss:20.93893895081425\n",
            " Iter:0 - Alpha:0.05 - Batch 174/249 - Min Loss:20.90 - Loss:20.90216704631186\n",
            " Iter:0 - Alpha:0.05 - Batch 175/249 - Min Loss:20.87 - Loss:20.870200636923865\n",
            " Iter:0 - Alpha:0.05 - Batch 176/249 - Min Loss:20.83 - Loss:20.831110964429943\n",
            " Iter:0 - Alpha:0.05 - Batch 177/249 - Min Loss:20.78 - Loss:20.789089300955563\n",
            " Iter:0 - Alpha:0.05 - Batch 178/249 - Min Loss:20.74 - Loss:20.742713231017284\n",
            " Iter:0 - Alpha:0.05 - Batch 179/249 - Min Loss:20.72 - Loss:20.723006706736662\n",
            " Iter:0 - Alpha:0.05 - Batch 180/249 - Min Loss:20.68 - Loss:20.68102095158839\n",
            " Iter:0 - Alpha:0.05 - Batch 181/249 - Min Loss:20.63 - Loss:20.638060861719183\n",
            " Iter:0 - Alpha:0.05 - Batch 182/249 - Min Loss:20.59 - Loss:20.59470399109266\n",
            " Iter:0 - Alpha:0.05 - Batch 183/249 - Min Loss:20.54 - Loss:20.54611537628786\n",
            " Iter:0 - Alpha:0.05 - Batch 184/249 - Min Loss:20.51 - Loss:20.51241932893738\n",
            " Iter:0 - Alpha:0.05 - Batch 185/249 - Min Loss:20.47 - Loss:20.478051582486437\n",
            " Iter:0 - Alpha:0.05 - Batch 186/249 - Min Loss:20.46 - Loss:20.463373830017265\n",
            " Iter:0 - Alpha:0.05 - Batch 187/249 - Min Loss:20.43 - Loss:20.43241322879335\n",
            " Iter:0 - Alpha:0.05 - Batch 188/249 - Min Loss:20.41 - Loss:20.415489639674075\n",
            " Iter:0 - Alpha:0.05 - Batch 189/249 - Min Loss:20.38 - Loss:20.382415841757297\n",
            " Iter:0 - Alpha:0.05 - Batch 190/249 - Min Loss:20.35 - Loss:20.35636952438826\n",
            " Iter:0 - Alpha:0.05 - Batch 191/249 - Min Loss:20.32 - Loss:20.323261107001173\n",
            " Iter:0 - Alpha:0.05 - Batch 192/249 - Min Loss:20.29 - Loss:20.29493752201367\n",
            " Iter:0 - Alpha:0.05 - Batch 193/249 - Min Loss:20.23 - Loss:20.231706936402226\n",
            " Iter:0 - Alpha:0.05 - Batch 194/249 - Min Loss:20.21 - Loss:20.21432965474384\n",
            " Iter:0 - Alpha:0.05 - Batch 195/249 - Min Loss:20.21 - Loss:20.210144050121418\n",
            " Iter:0 - Alpha:0.05 - Batch 196/249 - Min Loss:20.16 - Loss:20.168569648346853\n",
            " Iter:0 - Alpha:0.05 - Batch 197/249 - Min Loss:20.14 - Loss:20.142011333499262\n",
            " Iter:0 - Alpha:0.05 - Batch 198/249 - Min Loss:20.12 - Loss:20.125140346198748\n",
            " Iter:0 - Alpha:0.05 - Batch 199/249 - Min Loss:20.08 - Loss:20.087380807123058\n",
            " Iter:0 - Alpha:0.05 - Batch 200/249 - Min Loss:20.04 - Loss:20.04318704221147\n",
            " Iter:0 - Alpha:0.05 - Batch 201/249 - Min Loss:20.01 - Loss:20.016876269715105\n",
            " Iter:0 - Alpha:0.05 - Batch 202/249 - Min Loss:19.99 - Loss:19.993609763489637\n",
            " Iter:0 - Alpha:0.05 - Batch 203/249 - Min Loss:19.95 - Loss:19.95958895363022\n",
            " Iter:0 - Alpha:0.05 - Batch 204/249 - Min Loss:19.92 - Loss:19.926210041225872\n",
            " Iter:0 - Alpha:0.05 - Batch 205/249 - Min Loss:19.89 - Loss:19.897226008405745\n",
            " Iter:0 - Alpha:0.05 - Batch 206/249 - Min Loss:19.85 - Loss:19.858399448651905\n",
            " Iter:0 - Alpha:0.05 - Batch 207/249 - Min Loss:19.82 - Loss:19.825156772682394\n",
            " Iter:0 - Alpha:0.05 - Batch 208/249 - Min Loss:19.79 - Loss:19.791423468702167\n",
            " Iter:0 - Alpha:0.05 - Batch 209/249 - Min Loss:19.74 - Loss:19.748426133139297\n",
            " Iter:0 - Alpha:0.05 - Batch 210/249 - Min Loss:19.70 - Loss:19.70684081157403\n",
            " Iter:0 - Alpha:0.05 - Batch 211/249 - Min Loss:19.65 - Loss:19.656149451479525\n",
            " Iter:0 - Alpha:0.05 - Batch 212/249 - Min Loss:19.61 - Loss:19.615069526880045\n",
            " Iter:0 - Alpha:0.05 - Batch 213/249 - Min Loss:19.58 - Loss:19.582103310840218\n",
            " Iter:0 - Alpha:0.05 - Batch 214/249 - Min Loss:19.55 - Loss:19.551917829443145\n",
            " Iter:0 - Alpha:0.05 - Batch 215/249 - Min Loss:19.51 - Loss:19.510461166431092\n",
            " Iter:0 - Alpha:0.05 - Batch 216/249 - Min Loss:19.47 - Loss:19.475011337024338\n",
            " Iter:0 - Alpha:0.05 - Batch 217/249 - Min Loss:19.45 - Loss:19.451335316570166\n",
            " Iter:0 - Alpha:0.05 - Batch 218/249 - Min Loss:19.41 - Loss:19.41142036973254\n",
            " Iter:0 - Alpha:0.05 - Batch 219/249 - Min Loss:19.36 - Loss:19.36146522484553\n",
            " Iter:0 - Alpha:0.05 - Batch 220/249 - Min Loss:19.33 - Loss:19.33861295418467\n",
            " Iter:0 - Alpha:0.05 - Batch 221/249 - Min Loss:19.33 - Loss:19.332413479101064\n",
            " Iter:0 - Alpha:0.05 - Batch 222/249 - Min Loss:19.30 - Loss:19.30646915323804\n",
            " Iter:0 - Alpha:0.05 - Batch 223/249 - Min Loss:19.27 - Loss:19.27674800443457\n",
            " Iter:0 - Alpha:0.05 - Batch 224/249 - Min Loss:19.25 - Loss:19.251562163392435\n",
            " Iter:0 - Alpha:0.05 - Batch 225/249 - Min Loss:19.22 - Loss:19.222437561099124\n",
            " Iter:0 - Alpha:0.05 - Batch 226/249 - Min Loss:19.18 - Loss:19.18836632229978\n",
            " Iter:0 - Alpha:0.05 - Batch 227/249 - Min Loss:19.16 - Loss:19.162084970086052\n",
            " Iter:0 - Alpha:0.05 - Batch 228/249 - Min Loss:19.14 - Loss:19.149911547882425\n",
            " Iter:0 - Alpha:0.05 - Batch 229/249 - Min Loss:19.12 - Loss:19.1219394343792\n",
            " Iter:0 - Alpha:0.05 - Batch 230/249 - Min Loss:19.09 - Loss:19.096148635990602\n",
            " Iter:0 - Alpha:0.05 - Batch 231/249 - Min Loss:19.08 - Loss:19.081140852678754\n",
            " Iter:0 - Alpha:0.05 - Batch 232/249 - Min Loss:19.05 - Loss:19.053406614162057\n",
            " Iter:0 - Alpha:0.05 - Batch 233/249 - Min Loss:19.03 - Loss:19.03693768081677\n",
            " Iter:0 - Alpha:0.05 - Batch 234/249 - Min Loss:19.00 - Loss:19.009419641222927\n",
            " Iter:0 - Alpha:0.05 - Batch 235/249 - Min Loss:18.97 - Loss:18.97683561933004\n",
            " Iter:0 - Alpha:0.05 - Batch 236/249 - Min Loss:18.94 - Loss:18.940971848831524\n",
            " Iter:0 - Alpha:0.05 - Batch 237/249 - Min Loss:18.91 - Loss:18.9180874535922\n",
            " Iter:0 - Alpha:0.05 - Batch 238/249 - Min Loss:18.90 - Loss:18.901568132487206\n",
            " Iter:0 - Alpha:0.05 - Batch 239/249 - Min Loss:18.88 - Loss:18.885853616967232\n",
            " Iter:0 - Alpha:0.05 - Batch 240/249 - Min Loss:18.87 - Loss:18.87138521302166\n",
            " Iter:0 - Alpha:0.05 - Batch 241/249 - Min Loss:18.83 - Loss:18.835558989911696\n",
            " Iter:0 - Alpha:0.05 - Batch 242/249 - Min Loss:18.80 - Loss:18.807088870947275\n",
            " Iter:0 - Alpha:0.05 - Batch 244/249 - Min Loss:18.77 - Loss:18.783188527854637\n",
            " Iter:0 - Alpha:0.05 - Batch 245/249 - Min Loss:18.76 - Loss:18.764469185299056\n",
            " Iter:0 - Alpha:0.05 - Batch 246/249 - Min Loss:18.74 - Loss:18.74507008499201\n",
            " Iter:0 - Alpha:0.05 - Batch 247/249 - Min Loss:18.72 - Loss:18.72202504887896\n",
            " Iter:0 - Alpha:0.05 - Batch 248/249 - Min Loss:18.69 - Loss:18.695901177432972\n",
            " Iter:0 - Alpha:0.05 - Batch 249/249 - Min Loss:18.67 - Loss:18.672448412749706\n",
            " Iter:1 - Alpha:0.049 - Batch 1/249 - Min Loss:13.02 - Loss:13.025888771112934 - her the the the the the the the the the the the the the the the the th\n",
            " Iter:1 - Alpha:0.049 - Batch 3/249 - Min Loss:12.86 - Loss:12.911852216643139\n",
            " Iter:1 - Alpha:0.049 - Batch 4/249 - Min Loss:12.77 - Loss:12.779643901134486\n",
            " Iter:2 - Alpha:0.049 - Batch 4/249 - Min Loss:12.69 - Loss:12.861306794576533\n",
            " Iter:2 - Alpha:0.049 - Batch 100/249 - Min Loss:12.54 - Loss:12.553837414241563\n",
            " Iter:2 - Alpha:0.049 - Batch 202/249 - Min Loss:12.54 - Loss:12.54634211352977\n",
            " Iter:2 - Alpha:0.049 - Batch 203/249 - Min Loss:12.54 - Loss:12.545861505157209\n",
            " Iter:2 - Alpha:0.049 - Batch 204/249 - Min Loss:12.53 - Loss:12.539544475109949\n",
            " Iter:2 - Alpha:0.049 - Batch 205/249 - Min Loss:12.53 - Loss:12.538158626236882\n",
            " Iter:2 - Alpha:0.049 - Batch 206/249 - Min Loss:12.53 - Loss:12.531453875874227\n",
            " Iter:2 - Alpha:0.049 - Batch 207/249 - Min Loss:12.52 - Loss:12.522510778738871\n",
            " Iter:2 - Alpha:0.049 - Batch 208/249 - Min Loss:12.51 - Loss:12.5158004289451\n",
            " Iter:2 - Alpha:0.049 - Batch 209/249 - Min Loss:12.50 - Loss:12.50658976071825\n",
            " Iter:2 - Alpha:0.049 - Batch 210/249 - Min Loss:12.49 - Loss:12.497212397307786\n",
            " Iter:2 - Alpha:0.049 - Batch 211/249 - Min Loss:12.48 - Loss:12.4801470360593\n",
            " Iter:2 - Alpha:0.049 - Batch 212/249 - Min Loss:12.47 - Loss:12.472410142769563\n",
            " Iter:2 - Alpha:0.049 - Batch 213/249 - Min Loss:12.46 - Loss:12.466821255993375\n",
            " Iter:2 - Alpha:0.049 - Batch 214/249 - Min Loss:12.46 - Loss:12.46250302693015\n",
            " Iter:2 - Alpha:0.049 - Batch 215/249 - Min Loss:12.45 - Loss:12.450562994682569\n",
            " Iter:2 - Alpha:0.049 - Batch 217/249 - Min Loss:12.44 - Loss:12.44712729858359\n",
            " Iter:2 - Alpha:0.049 - Batch 218/249 - Min Loss:12.44 - Loss:12.440302120344606\n",
            " Iter:2 - Alpha:0.049 - Batch 219/249 - Min Loss:12.42 - Loss:12.425904198404831\n",
            " Iter:2 - Alpha:0.049 - Batch 249/249 - Min Loss:12.42 - Loss:12.473358614379077\n",
            " Iter:3 - Alpha:0.048 - Batch 1/249 - Min Loss:11.96 - Loss:11.96816271151561 - hend theres, and theres, and theres, and theres, and theres, and there\n",
            " Iter:3 - Alpha:0.048 - Batch 214/249 - Min Loss:11.94 - Loss:11.946587600476539\n",
            " Iter:3 - Alpha:0.048 - Batch 215/249 - Min Loss:11.93 - Loss:11.933923047280956\n",
            " Iter:3 - Alpha:0.048 - Batch 217/249 - Min Loss:11.92 - Loss:11.926656502973673\n",
            " Iter:3 - Alpha:0.048 - Batch 218/249 - Min Loss:11.91 - Loss:11.917809154684457\n",
            " Iter:3 - Alpha:0.048 - Batch 223/249 - Min Loss:11.90 - Loss:11.907968459614233\n",
            " Iter:3 - Alpha:0.048 - Batch 224/249 - Min Loss:11.90 - Loss:11.902355400459102\n",
            " Iter:3 - Alpha:0.048 - Batch 225/249 - Min Loss:11.89 - Loss:11.898399616347808\n",
            " Iter:3 - Alpha:0.048 - Batch 236/249 - Min Loss:11.89 - Loss:11.896736737502133\n",
            " Iter:4 - Alpha:0.048 - Batch 4/249 - Min Loss:11.89 - Loss:11.93749047561051\n",
            " Iter:4 - Alpha:0.048 - Batch 25/249 - Min Loss:11.67 - Loss:11.710709419035581\n",
            " Iter:4 - Alpha:0.048 - Batch 31/249 - Min Loss:11.60 - Loss:11.655038473490318\n",
            " Iter:4 - Alpha:0.048 - Batch 33/249 - Min Loss:11.60 - Loss:11.622026031347389\n",
            " Iter:4 - Alpha:0.048 - Batch 34/249 - Min Loss:11.58 - Loss:11.584410536097456\n",
            " Iter:4 - Alpha:0.048 - Batch 55/249 - Min Loss:11.56 - Loss:11.59348565034329\n",
            " Iter:4 - Alpha:0.048 - Batch 56/249 - Min Loss:11.55 - Loss:11.553452091216283\n",
            " Iter:4 - Alpha:0.048 - Batch 57/249 - Min Loss:11.52 - Loss:11.523624213684682\n",
            " Iter:4 - Alpha:0.048 - Batch 100/249 - Min Loss:11.51 - Loss:11.52019683227539\n",
            " Iter:4 - Alpha:0.048 - Batch 101/249 - Min Loss:11.50 - Loss:11.509577065372184\n",
            " Iter:4 - Alpha:0.048 - Batch 102/249 - Min Loss:11.49 - Loss:11.491519216923768\n",
            " Iter:4 - Alpha:0.048 - Batch 103/249 - Min Loss:11.48 - Loss:11.484576051174493\n",
            " Iter:4 - Alpha:0.048 - Batch 104/249 - Min Loss:11.48 - Loss:11.482251821619048\n",
            " Iter:4 - Alpha:0.048 - Batch 105/249 - Min Loss:11.47 - Loss:11.477400526998704\n",
            " Iter:4 - Alpha:0.048 - Batch 107/249 - Min Loss:11.46 - Loss:11.46564343952615\n",
            " Iter:4 - Alpha:0.048 - Batch 129/249 - Min Loss:11.45 - Loss:11.460378138592388\n",
            " Iter:4 - Alpha:0.048 - Batch 130/249 - Min Loss:11.45 - Loss:11.45460877668019\n",
            " Iter:4 - Alpha:0.048 - Batch 131/249 - Min Loss:11.43 - Loss:11.436848495211077\n",
            " Iter:4 - Alpha:0.048 - Batch 135/249 - Min Loss:11.42 - Loss:11.433507242920555\n",
            " Iter:4 - Alpha:0.048 - Batch 136/249 - Min Loss:11.41 - Loss:11.418981297647917\n",
            " Iter:4 - Alpha:0.048 - Batch 137/249 - Min Loss:11.41 - Loss:11.416048267430309\n",
            " Iter:4 - Alpha:0.048 - Batch 138/249 - Min Loss:11.39 - Loss:11.398926954900745\n",
            " Iter:4 - Alpha:0.048 - Batch 143/249 - Min Loss:11.39 - Loss:11.397617546563055\n",
            " Iter:4 - Alpha:0.048 - Batch 152/249 - Min Loss:11.39 - Loss:11.396587922054346\n",
            " Iter:4 - Alpha:0.048 - Batch 153/249 - Min Loss:11.38 - Loss:11.386413672865634\n",
            " Iter:4 - Alpha:0.048 - Batch 213/249 - Min Loss:11.38 - Loss:11.382570894809966\n",
            " Iter:4 - Alpha:0.048 - Batch 214/249 - Min Loss:11.37 - Loss:11.379202437332493\n",
            " Iter:4 - Alpha:0.048 - Batch 215/249 - Min Loss:11.36 - Loss:11.368017535797224\n",
            " Iter:4 - Alpha:0.048 - Batch 217/249 - Min Loss:11.35 - Loss:11.36308130222091\n",
            " Iter:4 - Alpha:0.048 - Batch 218/249 - Min Loss:11.35 - Loss:11.355348390014566\n",
            " Iter:4 - Alpha:0.048 - Batch 222/249 - Min Loss:11.34 - Loss:11.345817880695664\n",
            " Iter:4 - Alpha:0.048 - Batch 223/249 - Min Loss:11.34 - Loss:11.340187511215117\n",
            " Iter:4 - Alpha:0.048 - Batch 224/249 - Min Loss:11.33 - Loss:11.334937275117644\n",
            " Iter:4 - Alpha:0.048 - Batch 225/249 - Min Loss:11.33 - Loss:11.331100336921256\n",
            " Iter:4 - Alpha:0.048 - Batch 226/249 - Min Loss:11.32 - Loss:11.328961747495915\n",
            " Iter:4 - Alpha:0.048 - Batch 227/249 - Min Loss:11.32 - Loss:11.324704336305567\n",
            " Iter:4 - Alpha:0.048 - Batch 234/249 - Min Loss:11.32 - Loss:11.3277883008984\n",
            " Iter:4 - Alpha:0.048 - Batch 235/249 - Min Loss:11.32 - Loss:11.320809933553308\n",
            " Iter:4 - Alpha:0.048 - Batch 236/249 - Min Loss:11.31 - Loss:11.310224997032277\n",
            " Iter:4 - Alpha:0.048 - Batch 237/249 - Min Loss:11.30 - Loss:11.301638755334423\n",
            " Iter:4 - Alpha:0.048 - Batch 240/249 - Min Loss:11.29 - Loss:11.30339324171569\n",
            " Iter:4 - Alpha:0.048 - Batch 242/249 - Min Loss:11.29 - Loss:11.296226493349897\n",
            " Iter:5 - Alpha:0.047 - Batch 34/249 - Min Loss:11.29 - Loss:11.295798727310434\n",
            " Iter:5 - Alpha:0.047 - Batch 37/249 - Min Loss:11.28 - Loss:11.313966493696062\n",
            " Iter:5 - Alpha:0.047 - Batch 55/249 - Min Loss:11.28 - Loss:11.305744614606017\n",
            " Iter:5 - Alpha:0.047 - Batch 56/249 - Min Loss:11.26 - Loss:11.269090320237261\n",
            " Iter:5 - Alpha:0.047 - Batch 89/249 - Min Loss:11.24 - Loss:11.246903466540104\n",
            " Iter:5 - Alpha:0.047 - Batch 90/249 - Min Loss:11.23 - Loss:11.23040034411463\n",
            " Iter:5 - Alpha:0.047 - Batch 92/249 - Min Loss:11.21 - Loss:11.217792719376169\n",
            " Iter:5 - Alpha:0.047 - Batch 93/249 - Min Loss:11.18 - Loss:11.187492874212705\n",
            " Iter:5 - Alpha:0.047 - Batch 94/249 - Min Loss:11.17 - Loss:11.170589772552834\n",
            " Iter:5 - Alpha:0.047 - Batch 96/249 - Min Loss:11.15 - Loss:11.163111277550282\n",
            " Iter:5 - Alpha:0.047 - Batch 97/249 - Min Loss:11.15 - Loss:11.152788357987951\n",
            " Iter:5 - Alpha:0.047 - Batch 100/249 - Min Loss:11.14 - Loss:11.145558327649022\n",
            " Iter:5 - Alpha:0.047 - Batch 101/249 - Min Loss:11.13 - Loss:11.136507909341137\n",
            " Iter:5 - Alpha:0.047 - Batch 102/249 - Min Loss:11.11 - Loss:11.118644315584339\n",
            " Iter:5 - Alpha:0.047 - Batch 103/249 - Min Loss:11.11 - Loss:11.11005050903458\n",
            " Iter:5 - Alpha:0.047 - Batch 104/249 - Min Loss:11.10 - Loss:11.107330553053169\n",
            " Iter:5 - Alpha:0.047 - Batch 105/249 - Min Loss:11.10 - Loss:11.1055347009597\n",
            " Iter:5 - Alpha:0.047 - Batch 130/249 - Min Loss:11.09 - Loss:11.094912966915382\n",
            " Iter:5 - Alpha:0.047 - Batch 131/249 - Min Loss:11.07 - Loss:11.077304628994057\n",
            " Iter:5 - Alpha:0.047 - Batch 133/249 - Min Loss:11.06 - Loss:11.064413958151633\n",
            " Iter:5 - Alpha:0.047 - Batch 135/249 - Min Loss:11.05 - Loss:11.060112309362838\n",
            " Iter:5 - Alpha:0.047 - Batch 137/249 - Min Loss:11.04 - Loss:11.049502596095175\n",
            " Iter:5 - Alpha:0.047 - Batch 210/249 - Min Loss:11.03 - Loss:11.051644872804914\n",
            " Iter:5 - Alpha:0.047 - Batch 211/249 - Min Loss:11.03 - Loss:11.032906195670478\n",
            " Iter:5 - Alpha:0.047 - Batch 212/249 - Min Loss:11.02 - Loss:11.026525921686591\n",
            " Iter:5 - Alpha:0.047 - Batch 213/249 - Min Loss:11.01 - Loss:11.01957383583561\n",
            " Iter:5 - Alpha:0.047 - Batch 214/249 - Min Loss:11.01 - Loss:11.016464027923316\n",
            " Iter:5 - Alpha:0.047 - Batch 215/249 - Min Loss:11.00 - Loss:11.005740796702076\n",
            " Iter:5 - Alpha:0.047 - Batch 217/249 - Min Loss:10.99 - Loss:11.00009338291413\n",
            " Iter:5 - Alpha:0.047 - Batch 218/249 - Min Loss:10.99 - Loss:10.993414595406108\n",
            " Iter:5 - Alpha:0.047 - Batch 221/249 - Min Loss:10.98 - Loss:10.987128388397407\n",
            " Iter:5 - Alpha:0.047 - Batch 222/249 - Min Loss:10.98 - Loss:10.981680386549076\n",
            " Iter:5 - Alpha:0.047 - Batch 223/249 - Min Loss:10.97 - Loss:10.976160001229232\n",
            " Iter:5 - Alpha:0.047 - Batch 224/249 - Min Loss:10.97 - Loss:10.97123466134001\n",
            " Iter:5 - Alpha:0.047 - Batch 225/249 - Min Loss:10.96 - Loss:10.967957731498261\n",
            " Iter:5 - Alpha:0.047 - Batch 226/249 - Min Loss:10.96 - Loss:10.966287548690959\n",
            " Iter:5 - Alpha:0.047 - Batch 227/249 - Min Loss:10.95 - Loss:10.959771906206303\n",
            " Iter:5 - Alpha:0.047 - Batch 228/249 - Min Loss:10.95 - Loss:10.956842427154987\n",
            " Iter:5 - Alpha:0.047 - Batch 230/249 - Min Loss:10.95 - Loss:10.957712924458365\n",
            " Iter:5 - Alpha:0.047 - Batch 233/249 - Min Loss:10.95 - Loss:10.959567302341233\n",
            " Iter:5 - Alpha:0.047 - Batch 234/249 - Min Loss:10.95 - Loss:10.951658953912649\n",
            " Iter:5 - Alpha:0.047 - Batch 235/249 - Min Loss:10.94 - Loss:10.943100387617525\n",
            " Iter:5 - Alpha:0.047 - Batch 236/249 - Min Loss:10.93 - Loss:10.933564626378628\n",
            " Iter:5 - Alpha:0.047 - Batch 237/249 - Min Loss:10.92 - Loss:10.926709504993909\n",
            " Iter:6 - Alpha:0.047 - Batch 25/249 - Min Loss:10.92 - Loss:10.999370163894985\n",
            " Iter:6 - Alpha:0.047 - Batch 26/249 - Min Loss:10.88 - Loss:10.881101028873612\n",
            " Iter:6 - Alpha:0.047 - Batch 37/249 - Min Loss:10.87 - Loss:10.890244017637709\n",
            " Iter:6 - Alpha:0.047 - Batch 52/249 - Min Loss:10.86 - Loss:10.871406055131486\n",
            " Iter:6 - Alpha:0.047 - Batch 53/249 - Min Loss:10.85 - Loss:10.850734227239277\n",
            " Iter:6 - Alpha:0.047 - Batch 54/249 - Min Loss:10.84 - Loss:10.844342750653146\n",
            " Iter:6 - Alpha:0.047 - Batch 55/249 - Min Loss:10.82 - Loss:10.82964928153141\n",
            " Iter:6 - Alpha:0.047 - Batch 56/249 - Min Loss:10.80 - Loss:10.806095326510157\n",
            " Iter:6 - Alpha:0.047 - Batch 100/249 - Min Loss:10.78 - Loss:10.794403402442638\n",
            " Iter:6 - Alpha:0.047 - Batch 101/249 - Min Loss:10.78 - Loss:10.782537072245798\n",
            " Iter:6 - Alpha:0.047 - Batch 102/249 - Min Loss:10.76 - Loss:10.76771739344167\n",
            " Iter:6 - Alpha:0.047 - Batch 103/249 - Min Loss:10.76 - Loss:10.761370722904894\n",
            " Iter:6 - Alpha:0.047 - Batch 105/249 - Min Loss:10.75 - Loss:10.75871675762743\n",
            " Iter:6 - Alpha:0.047 - Batch 137/249 - Min Loss:10.74 - Loss:10.754060964622065\n",
            " Iter:6 - Alpha:0.047 - Batch 153/249 - Min Loss:10.74 - Loss:10.74831765925302\n",
            " Iter:6 - Alpha:0.047 - Batch 208/249 - Min Loss:10.74 - Loss:10.74544211428577\n",
            " Iter:6 - Alpha:0.047 - Batch 209/249 - Min Loss:10.73 - Loss:10.738573646258345\n",
            " Iter:6 - Alpha:0.047 - Batch 210/249 - Min Loss:10.73 - Loss:10.731406122926327\n",
            " Iter:6 - Alpha:0.047 - Batch 211/249 - Min Loss:10.71 - Loss:10.712558738937219\n",
            " Iter:6 - Alpha:0.047 - Batch 212/249 - Min Loss:10.70 - Loss:10.706112678395735\n",
            " Iter:6 - Alpha:0.047 - Batch 213/249 - Min Loss:10.69 - Loss:10.69988882680964\n",
            " Iter:6 - Alpha:0.047 - Batch 214/249 - Min Loss:10.69 - Loss:10.697287899706241\n",
            " Iter:6 - Alpha:0.047 - Batch 215/249 - Min Loss:10.68 - Loss:10.687186208038334\n",
            " Iter:6 - Alpha:0.047 - Batch 216/249 - Min Loss:10.68 - Loss:10.680354021789618\n",
            " Iter:6 - Alpha:0.047 - Batch 217/249 - Min Loss:10.68 - Loss:10.680158837792247\n",
            " Iter:6 - Alpha:0.047 - Batch 218/249 - Min Loss:10.67 - Loss:10.673939824307038\n",
            " Iter:6 - Alpha:0.047 - Batch 219/249 - Min Loss:10.66 - Loss:10.66218354004966\n",
            " Iter:6 - Alpha:0.047 - Batch 221/249 - Min Loss:10.66 - Loss:10.665572687123563\n",
            " Iter:6 - Alpha:0.047 - Batch 222/249 - Min Loss:10.66 - Loss:10.660573817774315\n",
            " Iter:6 - Alpha:0.047 - Batch 223/249 - Min Loss:10.65 - Loss:10.655508118863366\n",
            " Iter:6 - Alpha:0.047 - Batch 224/249 - Min Loss:10.64 - Loss:10.649569776815541\n",
            " Iter:6 - Alpha:0.047 - Batch 225/249 - Min Loss:10.64 - Loss:10.644235759358205\n",
            " Iter:6 - Alpha:0.047 - Batch 226/249 - Min Loss:10.64 - Loss:10.641910683697617\n",
            " Iter:6 - Alpha:0.047 - Batch 227/249 - Min Loss:10.63 - Loss:10.63576652566022\n",
            " Iter:6 - Alpha:0.047 - Batch 228/249 - Min Loss:10.63 - Loss:10.633937947917275\n",
            " Iter:6 - Alpha:0.047 - Batch 230/249 - Min Loss:10.63 - Loss:10.632851510791031\n",
            " Iter:6 - Alpha:0.047 - Batch 233/249 - Min Loss:10.63 - Loss:10.634243531165238\n",
            " Iter:6 - Alpha:0.047 - Batch 234/249 - Min Loss:10.62 - Loss:10.625880982982418\n",
            " Iter:6 - Alpha:0.047 - Batch 235/249 - Min Loss:10.61 - Loss:10.618171866373872\n",
            " Iter:6 - Alpha:0.047 - Batch 236/249 - Min Loss:10.61 - Loss:10.614117383481885\n",
            " Iter:7 - Alpha:0.046 - Batch 4/249 - Min Loss:10.61 - Loss:10.639774523877929\n",
            " Iter:7 - Alpha:0.046 - Batch 25/249 - Min Loss:10.56 - Loss:10.63215443709742\n",
            " Iter:7 - Alpha:0.046 - Batch 50/249 - Min Loss:10.52 - Loss:10.54478921940455\n",
            " Iter:7 - Alpha:0.046 - Batch 51/249 - Min Loss:10.50 - Loss:10.506901952815788\n",
            " Iter:7 - Alpha:0.046 - Batch 52/249 - Min Loss:10.50 - Loss:10.505238917069232\n",
            " Iter:7 - Alpha:0.046 - Batch 53/249 - Min Loss:10.47 - Loss:10.479046803999461\n",
            " Iter:7 - Alpha:0.046 - Batch 54/249 - Min Loss:10.46 - Loss:10.465003558444366\n",
            " Iter:7 - Alpha:0.046 - Batch 55/249 - Min Loss:10.45 - Loss:10.451869444117891\n",
            " Iter:7 - Alpha:0.046 - Batch 56/249 - Min Loss:10.42 - Loss:10.424349791185957\n",
            " Iter:7 - Alpha:0.046 - Batch 217/249 - Min Loss:10.40 - Loss:10.405030121295288\n",
            " Iter:7 - Alpha:0.046 - Batch 218/249 - Min Loss:10.39 - Loss:10.399731309757378\n",
            " Iter:7 - Alpha:0.046 - Batch 221/249 - Min Loss:10.38 - Loss:10.392509114339108\n",
            " Iter:7 - Alpha:0.046 - Batch 222/249 - Min Loss:10.38 - Loss:10.388150791460712\n",
            " Iter:7 - Alpha:0.046 - Batch 223/249 - Min Loss:10.38 - Loss:10.382787251615675\n",
            " Iter:7 - Alpha:0.046 - Batch 224/249 - Min Loss:10.37 - Loss:10.376638158547895\n",
            " Iter:7 - Alpha:0.046 - Batch 225/249 - Min Loss:10.37 - Loss:10.370642910690153\n",
            " Iter:7 - Alpha:0.046 - Batch 226/249 - Min Loss:10.36 - Loss:10.368273265433587\n",
            " Iter:7 - Alpha:0.046 - Batch 233/249 - Min Loss:10.36 - Loss:10.37270574846897\n",
            " Iter:7 - Alpha:0.046 - Batch 234/249 - Min Loss:10.36 - Loss:10.36354535916619\n",
            " Iter:7 - Alpha:0.046 - Batch 235/249 - Min Loss:10.35 - Loss:10.356103717854003\n",
            " Iter:7 - Alpha:0.046 - Batch 236/249 - Min Loss:10.35 - Loss:10.350516150005124\n",
            " Iter:8 - Alpha:0.046 - Batch 4/249 - Min Loss:10.34 - Loss:10.347544134461526\n",
            " Iter:8 - Alpha:0.046 - Batch 51/249 - Min Loss:10.32 - Loss:10.325147612812179\n",
            " Iter:8 - Alpha:0.046 - Batch 52/249 - Min Loss:10.32 - Loss:10.32380047698891\n",
            " Iter:8 - Alpha:0.046 - Batch 53/249 - Min Loss:10.30 - Loss:10.303471771315444\n",
            " Iter:8 - Alpha:0.046 - Batch 54/249 - Min Loss:10.29 - Loss:10.297303536340769\n",
            " Iter:8 - Alpha:0.046 - Batch 55/249 - Min Loss:10.28 - Loss:10.288745015178314\n",
            " Iter:8 - Alpha:0.046 - Batch 56/249 - Min Loss:10.26 - Loss:10.265505163471389\n",
            " Iter:8 - Alpha:0.046 - Batch 57/249 - Min Loss:10.25 - Loss:10.250160915438341\n",
            " Iter:8 - Alpha:0.046 - Batch 218/249 - Min Loss:10.25 - Loss:10.254641723145166\n",
            " Iter:8 - Alpha:0.046 - Batch 222/249 - Min Loss:10.24 - Loss:10.2463827490572\n",
            " Iter:8 - Alpha:0.046 - Batch 223/249 - Min Loss:10.24 - Loss:10.241216706418147\n",
            " Iter:8 - Alpha:0.046 - Batch 224/249 - Min Loss:10.23 - Loss:10.23550285074425\n",
            " Iter:8 - Alpha:0.046 - Batch 225/249 - Min Loss:10.23 - Loss:10.230025864233134\n",
            " Iter:8 - Alpha:0.046 - Batch 226/249 - Min Loss:10.22 - Loss:10.227572703077831\n",
            " Iter:8 - Alpha:0.046 - Batch 235/249 - Min Loss:10.22 - Loss:10.225017595042756\n",
            " Iter:8 - Alpha:0.046 - Batch 236/249 - Min Loss:10.21 - Loss:10.219474230425707\n",
            " Iter:9 - Alpha:0.045 - Batch 222/249 - Min Loss:10.21 - Loss:10.216623388711389\n",
            " Iter:9 - Alpha:0.045 - Batch 223/249 - Min Loss:10.21 - Loss:10.211296117199229\n",
            " Iter:9 - Alpha:0.045 - Batch 224/249 - Min Loss:10.20 - Loss:10.205694702954577\n",
            " Iter:9 - Alpha:0.045 - Batch 225/249 - Min Loss:10.20 - Loss:10.200093044743422\n",
            " Iter:9 - Alpha:0.045 - Batch 226/249 - Min Loss:10.19 - Loss:10.196741582361025\n",
            " Iter:9 - Alpha:0.045 - Batch 227/249 - Min Loss:10.19 - Loss:10.192933571655582\n",
            " Iter:9 - Alpha:0.045 - Batch 228/249 - Min Loss:10.19 - Loss:10.192528030836765\n",
            " Iter:9 - Alpha:0.045 - Batch 234/249 - Min Loss:10.19 - Loss:10.192964726592036\n",
            " Iter:9 - Alpha:0.045 - Batch 235/249 - Min Loss:10.18 - Loss:10.187445845296695\n",
            " Iter:9 - Alpha:0.045 - Batch 236/249 - Min Loss:10.18 - Loss:10.180675158123698\n",
            " Iter:9 - Alpha:0.045 - Batch 242/249 - Min Loss:10.17 - Loss:10.177516547278913\n",
            " Iter:10 - Alpha:0.045 - Batch 222/249 - Min Loss:10.17 - Loss:10.179094741453659\n",
            " Iter:10 - Alpha:0.045 - Batch 223/249 - Min Loss:10.17 - Loss:10.173215975108741\n",
            " Iter:10 - Alpha:0.045 - Batch 224/249 - Min Loss:10.16 - Loss:10.167508286346278\n",
            " Iter:10 - Alpha:0.045 - Batch 225/249 - Min Loss:10.16 - Loss:10.162385579680368\n",
            " Iter:10 - Alpha:0.045 - Batch 226/249 - Min Loss:10.15 - Loss:10.158477329327077\n",
            " Iter:10 - Alpha:0.045 - Batch 227/249 - Min Loss:10.15 - Loss:10.153018415828498\n",
            " Iter:10 - Alpha:0.045 - Batch 228/249 - Min Loss:10.15 - Loss:10.151151478978312\n",
            " Iter:10 - Alpha:0.045 - Batch 230/249 - Min Loss:10.14 - Loss:10.150457298592459\n",
            " Iter:10 - Alpha:0.045 - Batch 231/249 - Min Loss:10.14 - Loss:10.148094034580863\n",
            " Iter:10 - Alpha:0.045 - Batch 233/249 - Min Loss:10.14 - Loss:10.148934084314103\n",
            " Iter:10 - Alpha:0.045 - Batch 234/249 - Min Loss:10.14 - Loss:10.141599020614\n",
            " Iter:10 - Alpha:0.045 - Batch 235/249 - Min Loss:10.13 - Loss:10.135198660553108\n",
            " Iter:10 - Alpha:0.045 - Batch 236/249 - Min Loss:10.12 - Loss:10.12735270272132\n",
            " Iter:10 - Alpha:0.045 - Batch 237/249 - Min Loss:10.12 - Loss:10.122565487650919\n",
            " Iter:10 - Alpha:0.045 - Batch 240/249 - Min Loss:10.12 - Loss:10.12688068912441\n",
            " Iter:10 - Alpha:0.045 - Batch 241/249 - Min Loss:10.11 - Loss:10.119216913051648\n",
            " Iter:10 - Alpha:0.045 - Batch 242/249 - Min Loss:10.11 - Loss:10.115675096574979\n",
            " Iter:11 - Alpha:0.044 - Batch 2/249 - Min Loss:10.11 - Loss:10.142954264410974\n",
            " Iter:11 - Alpha:0.044 - Batch 236/249 - Min Loss:10.10 - Loss:10.11079866037127\n",
            " Iter:11 - Alpha:0.044 - Batch 237/249 - Min Loss:10.10 - Loss:10.108865376242138\n",
            " Iter:11 - Alpha:0.044 - Batch 240/249 - Min Loss:10.10 - Loss:10.114187214565092\n",
            " Iter:11 - Alpha:0.044 - Batch 241/249 - Min Loss:10.10 - Loss:10.106862696987486\n",
            " Iter:11 - Alpha:0.044 - Batch 242/249 - Min Loss:10.10 - Loss:10.105272047074063\n",
            " Iter:14 - Alpha:0.043 - Batch 21/249 - Min Loss:10.10 - Loss:10.744918723048924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-a9e27de9283a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-3550573a855b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(iterations)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbptt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cross_entropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_output\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"index_select\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreation_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, grad_origin)\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                     \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b5d1e5ac4017>\u001b[0m in \u001b[0;36mmm\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           \u001b[0mcreators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                           creation_op=\"mm\")\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Uv10Pds-SR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9bb8ca89-fb20-4a03-9a16-9b2007f5aaf5"
      },
      "source": [
        "print(generate_sample(n=500, init_char='\\n'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I avo to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkYHsezN2NjT",
        "colab_type": "text"
      },
      "source": [
        "## Задание 3\n",
        "\n",
        "Предложите свои варианты решения проблемы исчезающего градиента в RNN\n",
        "\n",
        "Deep Residual Learning (ResNets)\n",
        "\n",
        "Когда более глубокая сеть начинает сворачиваться, возникает проблема: с увеличением глубины сети точность сначала увеличивается, а затем быстро ухудшается. Снижение точности обучения показывает, что не все сети легко оптимизировать.\n",
        "\n",
        "\n",
        "Соединения быстрого доступа (shortcut connections) пропускают один или несколько слоев и выполняют сопоставление идентификаторов. Их выходы добавляются к выходам stacked layers. Используя ResNet, можно решить множество проблем, таких как:\n",
        "\n",
        "1. ResNet относительно легко оптимизировать: «простые» сети (которые просто складывают слои) показывают большую ошибку обучения, когда глубина увеличивается.\n",
        "2. ResNet позволяет относительно легко увеличить точность благодаря увеличению глубины, чего с другими сетями добиться сложнее.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8oWTAwN7Nub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}